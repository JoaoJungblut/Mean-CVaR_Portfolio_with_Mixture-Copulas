---
title: "The usage of dynamic copulas for portfolio optimization, worst-case cvar approach
  with cardinality constraints"
author: "Jo√£o Ramos Jungblut"
date: "`r Sys.Date()`"
output: html_document
---

# Set R project environment 

Overall, this code chunk is used to set up the R project environment, clean up the workspace, and clear any previous plots or graphs before executing further code in the R Markdown document.

```{r, echo=TRUE, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE}
# setting R project environment
my_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(my_dir)

# cleaning variables and graphs
rm(list=ls())
graphics.off()

```


# Load required packages

- **tidyverse**: Data manipulation and visualization.
- **tidyquant**: Financial data analysis.
- **rugarch**: Univariate GARCH modeling.
- **fGarch**: Multivariate GARCH modeling.
- **copula**: Copula modeling.
- **Rsolnp**: Nonlinear optimization.
- **fPortfolio**: Portfolio optimization.

```{r, echo=TRUE, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE}
# Load required packages
library(tidyverse)     # Data manipulation and visualization
library(tidyquant)     # Financial data analysis
library(rugarch)       # Univariate GARCH modeling
library(fGarch)        # Multivariate GARCH modeling
library(copula)        # Copula modeling
library(Rsolnp)        # Nonlinear optimization
library(fPortfolio)    # Portfolio optimization

```


# Importing modules

This code snippet is importing several modules or scripts into the current script or environment. Each module is sourced using the **source()** function, which reads and executes the code in the specified file.

```{r, echo=TRUE, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE}
# Importing modules
source("data_preprocessing.R")
source("garch_estimate.R")
source("copula_estimate.R")
source("portfolio_optimization.R")
source("performance_metrics.R")

```

Here's a breakdown of what each module might do:

## `data_processing.R`

The `data_processing.R` module contains functions for preprocessing data, specifically the `GetReturns` function. Let's explain this function in detail:

### `GetReturns(tickers, start_date)`

This function retrieves and calculates the returns for a given set of tickers from a specified start date.

#### Parameters:
- `tickers`: A character vector of ticker symbols representing the assets.
- `start_date`: A character or Date object specifying the start date of the data retrieval.

#### Description:
The function uses the `tq_get` function from the `tidyquant` package to retrieve the historical stock prices for the given tickers from the specified start date. It selects the columns "date", "symbol", and "adjusted" from the retrieved data. Then, it groups the data by symbol and calculates the logarithmic returns for each symbol using the `mutate` and `lag` functions from the `dplyr` package. The function removes the "adjusted" column and spreads the data to have columns for each symbol, with the corresponding returns. It replaces any missing values in the data with zeros using the `replace` function. Finally, it returns the processed data.

```{r, echo=TRUE, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE}
GetReturns <- function(tickers, start_date) {
  data <- tidyquant::tq_get(tickers, from = start_date) %>% 
    dplyr::select("date", "symbol", "adjusted") %>%
    dplyr::group_by(symbol) %>% 
    dplyr::mutate(return = log(adjusted) - log(dplyr::lag(adjusted))) %>% 
    dplyr::ungroup() %>% 
    dplyr::select(-adjusted) %>% 
    tidyr::spread(key = symbol, value = return) %>% 
    dplyr::mutate(dplyr::across(where(is.numeric), ~replace(., is.na(.), 0)))
  
  return(data)
}
```

Please note that the documentation assumes the availability of necessary packages and objects (e.g., `tidyquant`, `dplyr`, `tidyr`) and their proper loading prior to using these functions.



## `garch_estimate.R`

The `garch_estimate.R` module contains functions for estimating GARCH models and predicting future values based on the estimated models. Let's explain each function in detail:

### `FitGarch(returns)`

This function fits a GARCH model to a given set of returns.

#### Parameters:
- `returns`: A matrix or data frame containing the historical returns of assets.

#### Description:
The function initializes a GARCH specification using the `ugarchspec` function from the `rugarch` package. It specifies a symmetric GARCH(1,1) model with the "sstd" distribution. Then, it loops over each asset in the `returns` matrix and fits a GARCH model using the `ugarchfit` function. The function saves the residuals, sigma forecasts, GARCH coefficients, and uniform distribution values for each asset. Finally, it returns a list containing the results.

```{r, echo=TRUE, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE}
FitGarch <- function(returns){
  
  # Initialize the GARCH specification
  mod_garch <- try(rugarch::ugarchspec(variance.model = list(model = "sGARCH", 
                                                             garchOrder = c(1, 1),
                                                             variance.targeting = TRUE),
                                       mean.model = list(armaOrder = c(1, 0)),
                                       distribution.model = "sstd"),
                   silent = TRUE)
  
  # Matrix to save model coefficients, standard deviation and residuals
  unif_dist <- garch_pred <- sigma <- residuals <- matrix(nrow = nrow(returns), 
                                                          ncol = ncol(returns))
  garch_coef <- vector("list", length = ncol(returns))
  
  # Loop over each asset
  for(j in 1:ncol(returns)){
    # Fitting GARCH model
    garch_fit <- try(ugarchfit(mod_garch, data = returns[,j], solver = "hybrid"),
                     silent=TRUE)
    
    # Save residuals, sigma forecasts, GARCH coefficients, and uniform distribution values
    residuals[, j] <- garch_fit@fit$residuals
    sigma[, j] <- garch_fit@fit$sigma
    garch_coef[[j]] <- garch_fit@fit$coef
    unif_dist[, j] <- fGarch::psstd(q = residuals[, j] / sigma[, j],
                                    nu = garch_coef[[j]][6],
                                    xi = garch_coef[[j]][5])
  }
  
  # Create a list to store the results
  result <- list(residuals = residuals,
                 sigma = sigma,
                 garch_coef = garch_coef,
                 unif_dist = unif_dist)
  
  # Return the results
  return(result)
}

```

### `PredictGarch(returns, sigma, zsim, garch_coef, n_ahead = 252)`

This function predicts future returns and volatility using a fitted GARCH model.

#### Parameters:
- `returns`: A matrix or data frame containing the historical returns of assets.
- `sigma`: A matrix containing the historical volatility (sigma) forecasts.
- `zsim`: A matrix of standardized residuals generated from the mixture of copulas.
- `garch_coef`: A list containing the GARCH coefficients for each asset.
- `n_ahead`: The number of periods to predict ahead (default is 252, representing one year).

#### Description:
The function initializes matrices to store the predicted values for returns, mean, and volatility. It then iterates over each asset in the `returns` matrix. For each asset, it first retrieves the last observed return and volatility. It then performs forecasting for the first period (t = 1) using the GARCH coefficients and the ARMA model. Subsequently, it forecasts returns and volatility for periods t > 1 by iterating over the specified number of periods. The predicted returns are calculated based on the mean prediction, volatility prediction, and standardized residuals from the mixture of copulas. Finally, the function returns a list containing the predicted values.

```{r, echo=TRUE, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE}
PredictGarch <- function(returns, sigma, zsim, garch_coef, n_ahead = 252) {
  # Initialize matrices to store predicted values
  ret_pred <- mean_pred <- sigma_pred <- matrix(nrow = n_ahead, ncol = ncol(returns))
  
  for (j in 1:ncol(returns)) {
    # Get the last observed return and sigma
    ret_t <- as.numeric(returns[ncol(returns), j])
    sigma_t <- sigma[ncol(sigma), j]
    
    # Forecasting at t = 1
    sigma_pred[1, j] <- sqrt(garch_coef[[j]][7] +  # omega
                               garch_coef[[j]][3] * (ret_t)^2 +  # alpha1
                               garch_coef[[j]][4] * (sigma_t)^2)  # beta1
    mean_pred[1, j] <- garch_coef[[j]][1] + garch_coef[[j]][2] * ret_t  # mu and ar1
    ret_pred[1, j] <- mean_pred[1, j] + sigma_pred[1, j] * zsim[1, j]
    
    # Forecasting for t > 1
    for (i in 2:n_ahead) {
      sigma_pred[i, j] <- sqrt(garch_coef[[j]][7] +  # omega
                                 garch_coef[[j]][3] * (ret_pred[(i - 1), j])^2 +  # alpha1
                                 garch_coef[[j]][4] * (sigma_pred[(i - 1), j])^2)  # beta1
      mean_pred[i, j] <- garch_coef[[j]][1] + garch_coef[[j]][2] * ret_pred[(i - 1), j]  # mu and ar1
      ret_pred[i, j] <- mean_pred[i, j] + sigma_pred[i, j] * zsim[i, j]
    }
  }
  
  # Create a list to store the predicted values
  result <- list(sigma_pred = sigma_pred,
                 mean_pred = mean_pred,
                 ret_pred = ret_pred)
  
  return(result)
}

```

Please note that the documentation assumes the availability of necessary packages and objects (e.g., `rugarch`, `fGarch`) and their proper loading prior to using these functions.



## `copula_estimate.R`

The `copula_estimate.R` module contains several functions for estimating copula parameters and weights based on GARCH residuals. Here's a detailed explanation of each function:


### `LLCG(params, U, copC, copG, copt)`

This function calculates the negative log-likelihood of a mixture of copulas.

#### Parameters:
- `params`: A vector containing the copula parameters and weights to be estimated.
- `U`: A matrix of uniform distribution values (generated from GARCH residuals).
- `copC`: A Clayton copula object.
- `copG`: A Gumbel copula object.
- `copt`: A t copula object.

#### Description:
The function sets the copula parameters and weights based on the input `params`. It then calculates the log-likelihood of the mixture of copulas by evaluating the copula density functions for each copula (Clayton, Gumbel, and t) at the given uniform distribution values. The log-likelihood values are summed, and the negative sum is returned as the final result. In case there are infinite values in the log-likelihood, they are replaced with zero to avoid errors.

```{r, echo=TRUE, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE}
# Negative log-likelihood function for estimating copula weights and parameters
LLCG <- function(params, U, copC, copG, copt){ 
  # Set copula parameters
  slot(copC, "parameters") <- params[1]    # Initial Clayton parameter
  slot(copG, "parameters") <- params[2]    # Initial Gumbel parameter 
  slot(copt, "parameters") <- params[3:4]  # Initial t parameters (correlation and degrees of freedom)
  
  # Set copula weights
  pi1 <- params[5]  # Weight of Clayton copula
  pi2 <- params[6]  # Weight of Gumbel copula
  pi3 <- params[7]  # Weight of t copula
  
  # Calculate the log-likelihood function to be optimized
  opt <- log(pi1 * copula::dCopula(U, copC) + 
               pi2 * copula::dCopula(U, copG) + 
               pi3 * copula::dCopula(U, copt))
  
  # Handle infinite values in the log-likelihood
  if(any(is.infinite(opt))){
    opt[which(is.infinite(opt))] <- 0
  }
  
  # Return the negative sum of the log-likelihood
  -sum(opt)
}
```


### `eqfun(params, U, copC, copG, copt)`

This function ensures that the sum of copula weights is equal to 1.

#### Parameters:
- `params`: A vector containing the copula parameters and weights to be estimated.
- `U`: A matrix of uniform distribution values (generated from GARCH residuals).
- `copC`: A Clayton copula object.
- `copG`: A Gumbel copula object.
- `copt`: A t copula object.

#### Description:
The function calculates the sum of copula weights by summing the values in the `params` vector that correspond to the copula weights. It ensures that the sum is equal to 1 and returns the result. This function is used as a constraint in the optimization process to maintain the sum of weights.

```{r, echo=TRUE, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE}
# Constrain function to ensure sum(weights) = 1
eqfun <- function(params, U, copC, copG, copt){ 
  z <- params[5] + params[6] + params[7]
  return(z)
}

```

### `OptMixtureCopulas(unif_dist)`

This function estimates the parameters and weights for a mixture of copulas.

#### Parameters:
- `unif_dist`: A matrix of uniform distribution values (generated from GARCH residuals).

#### Description:
The function initializes the copula objects (Clayton, Gumbel, and t) with initial parameter values. It defines the lower and upper bounds for the copula parameters and weights. Then, using the `fitCopula` function, it estimates initial guesses for the copula parameters based on the provided uniform distribution values. Next, the function initializes the weights for each copula with initial guesses. Finally, it performs a non-linear constrained optimization using the `solnp` function from the `Rsolnp` package, optimizing the negative log-likelihood function `LLCG` with the constraint function `eqfun`. The optimized copula parameters and weights are returned as the final result.

```{r, echo=TRUE, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE}
OptMixtureCopulas <- function(unif_dist) {
  # Initialize copula objects
  copt <- copula::tCopula(param = 0.5, dim = ncol(unif_dist))  # t-Copula with parameter 0.5
  copC <- copula::claytonCopula(2, dim = ncol(unif_dist))      # Clayton copula with delta = 2
  copG <- copula::gumbelCopula(2, dim = ncol(unif_dist))       # Gumbel copula with theta = 2
  
  # Define lower and upper bounds for the copula parameters and weights
  lower <- c(0.1, 1, -0.9, (2 + .Machine$double.eps), 0, 0, 0)
  upper <- c(copC@param.upbnd, copG@param.upbnd, 1, 100, 1, 1, 1)
  
  ## Creating elliptical copula objects and estimating "initial guesses" for each copula parameter.
  # Then, we maximize loglikelihood of the linear combination of the three copulas
  par1 <- copula::fitCopula(copC, unif_dist, "itau", estimate.variance = TRUE)@estimate # Inversion of Kendall's tau for Clayton
  par2 <- copula::fitCopula(copG, unif_dist, "itau", estimate.variance = TRUE)@estimate # Inversion of Kendall's tau for Gumbel
  par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE)@estimate # MPL to estimate Degrees of Freedom (DF)
  
  # Initialize weights for copulas (initial guesses = 1/3 each)
  par6 <- par5 <- par4 <- 1/3
  
  ## Non-linear constrained optimization (RSOLNP)
  opt <- Rsolnp::solnp(pars = c(par1, par2, par3, par4, par5, par6),
                       fun = LLCG,
                       LB = lower,
                       UB = upper,
                       copt = copt,
                       copC = copC,
                       copG = copG,
                       U = unif_dist,
                       eqfun = eqfun,
                       eqB = c(1)) # RSOLNP
  
  ## Saving optimization parameters in a list
  cop_param <- opt$pars
  
  # Clayton, t, gumbel, and ctg variates matrix
  ctg <- Cc <- Cg <- Ct <- matrix(nrow = nrow(unif_dist), ncol = ncol(unif_dist))
  
  ## Generating copula variates
  Cc[, ] <- cop_param[5] * copula::rCopula(n = nrow(unif_dist),
                                           copula = copula::claytonCopula(param = cop_param[1],
                                                                          dim = ncol(unif_dist)))
  Cg[, ] <- cop_param[6] * copula::rCopula(n = nrow(unif_dist),
                                           copula = copula::gumbelCopula(param = cop_param[2],
                                                                         dim = ncol(unif_dist)))
  Ct[, ] <- cop_param[7] * copula::rCopula(n = nrow(unif_dist),
                                           copula = copula::tCopula(param = cop_param[3],
                                                                    df = cop_param[4],
                                                                    dim = ncol(unif_dist)))
  
  # Linear combination of copula varieties
  ctg <- Cc + Ct + Cg
  
  # Return the ctg matrix
  return(ctg)
}

```

### `ComputeZSim(copula_mixture, garch_coef)`

This function computes the zsim values for each column of the copula_mixture.

#### Parameters:
- `copula_mixture`: A matrix of copula variates generated from the mixture of copulas.
- `garch_coef`: A list of GARCH coefficients for each asset.

#### Description:
The function iterates over each column of the `copula_mixture` matrix. For each column, it computes the zsim values using the `qsstd` function from the `fGarch` package. The `qsstd` function takes the copula variates.

```{r, echo=TRUE, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE}
ComputeZSim <- function(copula_mixture, garch_coef) {
  # Create an empty matrix to store zsim values
  zsim <- matrix(nrow = nrow(copula_mixture), ncol = ncol(copula_mixture))
  
  # Compute zsim values for each column of copula_mixture
  for (j in 1:ncol(copula_mixture)) {
    # Compute zsim using qsstd function from fGarch package
    zsim[, j] <- fGarch::qsstd(copula_mixture[, j],
                               nu = garch_coef[[j]][6],
                               xi = garch_coef[[j]][5]) /
      sd(fGarch::qsstd(copula_mixture[, j], nu = garch_coef[[j]][6],
                       xi = garch_coef[[j]][5]))
  }
  
  # Return the zsim matrix
  return(zsim)
}

```

Please note that the documentation assumes the availability of necessary packages and objects (e.g., `copula`, `Rsolnp`,`fGarch`) and their proper loading prior to using these functions.



## `portfolio_optimization.R`

The `portfolio_optimization.R` module contains functions for portfolio optimization, specifically the `CVaROptimization` and `RetPortfolio` functions. Let's explain these functions in detail:

### `CVaROptimization(returns, Alpha = 0.025, TargetReturn = 0)`

This function performs portfolio optimization using the Conditional Value at Risk (CVaR) approach.

#### Parameters:
- `returns`: A matrix or data frame containing the historical returns of the assets.
- `Alpha`: A numeric value representing the confidence level for CVaR. The default value is 0.025, corresponding to a CVaR_0.975 (the 97.5th percentile).
- `TargetReturn`: A numeric value representing the desired daily target return for the portfolio. The default value is 0, indicating no specific target return constraint.

#### Description:
The function uses the `fPortfolio` package to perform portfolio optimization. It first creates a portfolio specification object using `portfolioSpec` function from `fPortfolio`. Then, it sets the portfolio type as CVaR, the solver as "solveRglpk.CVAR" (a linear programming solver for CVaR optimization), the CVaR alpha level as `Alpha`, and the target return constraint as `TargetReturn`. Next, it converts the `returns` data into a time series object using `as.timeSeries`. Finally, it optimizes the portfolio using the efficientPortfolio function from `fPortfolio`, considering the long-only constraint. The resulting weights of the optimized portfolio are stored and returned.

```{r, echo=TRUE, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE}
CVaROptimization <- function(returns, Alpha = 0.025, TargetReturn = 0) {
  frontierSpec <- fPortfolio::portfolioSpec()  # Portfolio specification for optimization
  fPortfolio::setType(frontierSpec) <- "CVaR"  # Set portfolio type as CVaR
  fPortfolio::setSolver(frontierSpec) <- "solveRglpk.CVAR"  # Use linear programming solver for CVaR optimization
  fPortfolio::setAlpha(frontierSpec) <- Alpha  # Set CVaR alpha level as 0.025 (CVaR_0.975)
  fPortfolio::setTargetReturn(frontierSpec) <- TargetReturn  # Set the daily target return constraint
  
  # Create time series object
  returnfPort <- as.timeSeries(returns)
  
  # Optimizing portfolio using K simulated returns for each asset
  frontier1g <- fPortfolio::efficientPortfolio(data = returnfPort,
                                               spec = frontierSpec,
                                               constraints = "LongOnly")
  
  # Storing resulting weights
  cvar_opt <- rbind(fPortfolio::getWeights(frontier1g))
  
  # Return portfolio weights
  return(cvar_opt)
}

```

### `RetPortfolio(returns, weights)`

This function calculates the returns of a portfolio given the historical returns and the portfolio weights.

#### Parameters:
- `returns`: A matrix or data frame containing the historical returns of the assets.
- `weights`: A numeric vector representing the weights of the assets in the portfolio.

#### Description:
The function takes the matrix of `returns` and multiplies it by the transpose of the `weights` vector to calculate the portfolio returns. The resulting portfolio returns are returned.

```{r, echo=TRUE, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE}
RetPortfolio <- function(returns, weights){
  
  portfolio_returns <- returns %*% t(weights)
  
  return(portfolio_returns)
}
```

Please note that the documentation assumes the availability of necessary packages and objects (e.g., `fPortfolio`) and their proper loading prior to using these functions.



# Importing data and calculating returns
The following code snippet demonstrates how to retrieve stock returns for a list of tickers and a specific start date.

The `tickers` variable is defined as a character vector containing the stock tickers of interest. The `start_date` variable represents the desired start date for data retrieval.

The code then calls the `GetReturns` function, passing the `tickers` and `start_date` as arguments. The function retrieves the stock returns for the specified tickers and start date, storing the result in the `returns` variable.

Please note that the `GetReturns` function is assumed to be imported from `data_preprocessing.R` module.


```{r, echo=TRUE, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE}
# Define the list of stock tickers and the start date for data retrieval
tickers <- c("PETR4.SA", "VALE3.SA", "ITUB4.SA", "BBAS3.SA", "ABEV3.SA", 
             "BBDC4.SA", "GRND3.SA", "SMTO3.SA", "SLCE3.SA", "VIVT3.SA")
start_date <- "2000-01-01"

# Retrieve the stock returns for the given tickers and start date
returns <- GetReturns(tickers = tickers, start_date = start_date)
head(returns)

```



# Creating auxiliary matrices and list

- `N` is assigned the value of the number of columns in the `returns` matrix minus one, representing the number of assets in the portfolio.

- `K` is assigned the value of 252, which denotes the window size for GARCH estimation. This indicates that the code will perform calculations using a rolling window of 252 observations.

- `index_vector` is created using the `seq()` function. It generates a vector ranging from 1 to the number of rows in the `returns` matrix, with an increment of K. This vector serves as an index for rolling optimization.

- `names_vector` is assigned the names of the columns in the `returns` matrix, excluding the first column. It provides a reference for the asset names.

- `weights` is initialized as a matrix with the same number of rows as the `index_vector` vector and with the same number of columns as the `returns` matrix. It is used to store the portfolio weights for each asset.

- `portfolio_returns` is initialized as a matrix with the same number of rows as the `index_vector` matrix and one column. It is used to store the portfolio returns.

- The first K rows of `portfolio_returns` are set to zero, initializing them as zero. This step is likely performed to indicate that the calculations for portfolio returns will start from the K+1 row forwards.

```{r, echo=TRUE, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE}
# Creating auxiliary matrices and list
N <- base::ncol(returns) - 1   # Number of assets
K <- 252                 # Window size for GARCH estimation
index_vector <- seq(1, nrow(returns), by = K)  # Index vector for rolling optimization
names_vector <- names(returns)[-1]   # Asset names for reference
weights <- matrix(nrow = length(index_vector), ncol = N) # Create a matrix to store the weights for each asset in the portfolio
colnames(weights) <- names_vector # Set the column names of the weights matrix as the asset names
weights[1,] <-  0 # Initialize the first row of the weights matrix as all zeros
portfolio_returns <- matrix(nrow = nrow(returns), ncol = 1)  # Matrix to store portfolio returns
portfolio_returns[1:K, ] <- 0  # Initialize the first K rows as zero

```


# Iterating over n assets

The code snippet performs an iteration over a set of assets to optimize the portfolio using copula-based simulations. Here is a breakdown of the code with detailed explanations for each step:

- **Initialization**: First, we initialize a series of matrices and lists to store the forecasts and optimization results. This ensures that we have containers to hold the data generated during the iteration.

- **Iteration**: The iteration starts from the second index of the `index_vector` and loops through each asset. We use the `for` loop to iterate over the asset indices.

- **Calculations within the loop**:

  - *`ret_matrix_insample`*: We extract a subset of returns data for the specific asset. This allows us to work with the returns data for each asset individually.
  
  - *`assets_with_valid_returns`*: We create a logical vector indicating if each asset has sufficient data. This helps filter out assets with insufficient data, ensuring that we only consider assets with enough historical returns.
  
  - *`fit_garch`*: We fit a GARCH model to the subset of returns data using the `FitGarch()` function. This involves estimating the GARCH model parameters, including residuals, sigma forecasts, and GARCH coefficients. These parameters will be used for further calculations.
  
  - *`copulas_mixture`*: For each asset, we generate copula variates using the `OptMixtureCopulas()` function. This step involves optimizing the mixture of copulas based on the uniform distribution from the GARCH model. The resulting copula variates will be used to simulate the dependence structure of the asset returns.
  
  - *`zsim`*: We compute simulated standardized residuals using the optimized copula mixture and GARCH coefficients. This step combines the copula variates with the GARCH coefficients to generate standardized residuals, which will be used in predicting future returns.
  
  - *`ret_pred`*: Predictions for future returns, mean, and sigma are made based on the GARCH model and the copula variates. This step uses the GARCH model forecasts, simulated standardized residuals, and volatility estimates to generate predictions for the asset's future returns.
  
  - *`weights`*: We perform a CVaR (Conditional Value-at-Risk) optimization to determine the optimal portfolio weights. This optimization is done by the function `CVaROptimization()` using the simulated returns for each asset during the specific optimization period. The resulting weights are stored in a previously defined matrix. Assets without valid returns are assigned a weight of 0.
  
  - *`portfolio_returns`*: We calculate the portfolio returns based on the optimal weights using the `RetPortfolio()` function. This step involves applying the weights to the realized returns of the assets in the portfolio to calculate the daily portfolio returns. The resulting portfolio returns are stored in a previously defined matrix.
  
- **Continuation of iteration**: The iteration continues until all assets have been processed, ensuring that we go through the entire set of assets.


```{r, echo=TRUE, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE, results='hide'}
for (i in 2:length(index_vector)){
  
  # Establishing window interval in-sample
  t1 <- index_vector[i - 1]
  t2 <- index_vector[i] - 1
  
  # Convert the in-sample returns data to a matrix format
  ret_matrix_insample <- as.matrix(returns[t1:t2, -1])
  
  # Create a logical vector indicating if each asset has sufficient data
  assets_with_valid_returns <- colMeans(ret_matrix_insample[1:10,]) != 0 
  
  # Subset the returns matrix and asset names based on assets with sufficient data
  ret_matrix_insample <- ret_matrix_insample[, assets_with_valid_returns]
  
  # Fit the GARCH model to the returns data
  fit_garch <- FitGarch(returns = ret_matrix_insample)
  
  # Optimize the mixture of copulas using the uniform distribution from the GARCH model
  copulas_mixture <- OptMixtureCopulas(unif_dist = fit_garch$unif_dist)
  
  # Compute simulated standardized residuals using the optimized copula mixture and GARCH coefficients
  zsim <- ComputeZSim(copula_mixture = copulas_mixture, garch_coef = fit_garch$garch_coef)
  
  # Predict future returns using the GARCH model, simulated residuals, and volatility estimates
  ret_pred <- PredictGarch(returns = ret_matrix_insample, 
                           sigma = fit_garch$sigma,
                           zsim = zsim,
                           garch_coef = fit_garch$garch_coef)$ret_pred
  
  # Perform CVaR optimization to determine the optimal portfolio weights
  weights[i, names_vector[assets_with_valid_returns]] <- CVaROptimization(returns = ret_pred)
  weights[i, names_vector[!assets_with_valid_returns]] <- 0
  
  # Establishing window interval in-sample
  t3 <- t1 + K
  t4 <- min(nrow(returns), t2+K)
  
  # Convert the realized returns data to a matrix format
  ret_matrix_outofsample <- as.matrix(returns[t3:t4, -1])
  
  # Calculate the portfolio returns based on the optimal weights
  portfolio_returns[t3:t4,] <- RetPortfolio(returns = ret_matrix_outofsample, 
                                            weights = rbind(weights[i,]))
}

```



# Analyzing Portfolio Performance

After optimizing the portfolio using copula-based simulations, we analyze its performance by performing the following steps:

1. **Converting to xts object**: We convert the `portfolio_returns` matrix to an `xts` object using the `xts()` function. This step ensures that the portfolio returns data is in a suitable format for further calculations.

2. **Calculating Sharpe ratio**: We calculate the annualized Sharpe ratio of the portfolio returns using the `SharpeRatio.annualized()` function. The Sharpe ratio measures the risk-adjusted return of an investment.

3. **Calculating annualized return**: We calculate the annualized return of the portfolio using the `Return.annualized()` function. This metric provides the average annual return over the investment period.

4. **Calculating cumulative return**: We calculate the cumulative return of the portfolio using the `Return.cumulative()` function. This metric represents the total return over the investment period.

5. **Calculating drawdowns**: We calculate the maximum drawdown of the portfolio using the `maxDrawdown()` function. Drawdown measures the peak-to-trough decline experienced by the portfolio.

6. **Printing the calculated metrics**: We print the calculated metrics (Sharpe ratio, annualized return, cumulative return, and drawdown) to the console using the `print()` function. This allows us to view the results of the performance analysis.

7. **Generating a performance summary graph**: We generate a performance summary graph using the `charts.PerformanceSummary()` function. This graph provides a visual representation of the portfolio's performance, including cumulative returns, drawdowns, and other performance metrics.

Make sure to have the required packages (`xts` and `PerformanceAnalytics`) installed and loaded before executing this code in your RMarkdown document.


```{r, echo=TRUE, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE}
# Convert the portfolio_returns matrix to an xts object
portfolio_returns_xts <- xts::xts(portfolio_returns, order.by = returns$date)

# Calculate Sharpe ratio
sharpe_ratio <- PerformanceAnalytics::SharpeRatio.annualized(portfolio_returns_xts)

# Calculate annualized return
annualized_return <- PerformanceAnalytics::Return.annualized(portfolio_returns_xts)

# Calculate cumulative return
cumulative_return <- PerformanceAnalytics::Return.cumulative(portfolio_returns_xts)

# Calculate drawdowns
drawdown <- PerformanceAnalytics::maxDrawdown(portfolio_returns_xts)

# Print the calculated metrics
print(sharpe_ratio)
print(annualized_return)
print(cumulative_return)
print(drawdown)

# Generate graph
PerformanceAnalytics::charts.PerformanceSummary(portfolio_returns_xts)
```

