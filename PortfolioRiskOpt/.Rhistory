# Realizando a otimização do portfólio
opt_portfolio <- portfolioFrontier(data, spec, constraints = constraints)
# Extraindo os pesos dos ativos no portfólio otimizado
weights <- getWeights(opt_portfolio)
# Visualizando a alocação de pesos
print(weights)
# Dados de retorno dos ativos
data <- as.timeSeries(returns)
data
# Definindo os parâmetros da otimização
nAssets <- ncol(data)
nAssets
spec <- portfolioSpec()
spec
fPortfolio::setType(frontierSpec) <- "CVaR"  # Set portfolio type as CVaR
fPortfolio::setSolver(frontierSpec) <- "solveRglpk.CVAR"  # Use linear programming solver for CVaR optimization
fPortfolio::setAlpha(frontierSpec) <- 0.025  # Set CVaR alpha level as 0.05 (CVaR_0.95)
fPortfolio::setTargetReturn(frontierSpec) <- targetReturn  #
fPortfolio::setType(spec) <- "CVaR"  # Set portfolio type as CVaR
fPortfolio::setSolver(spec) <- "solveRglpk.CVAR"  # Use linear programming solver for CVaR optimization
fPortfolio::setAlpha(spec) <- 0.025  # Set CVaR alpha level as 0.05 (CVaR_0.95)
fPortfolio::setTargetReturn(fspec) <- targetReturn  #
fPortfolio::setTargetReturn(sspec) <- targetReturn  #
fPortfolio::setTargetReturn(spec) <- targetReturn  #
spec
fPortfolio::`setNFrontierPoints<-200
)
{{}}
23232
2+2
)))
``
`
fPortfolio::setNFrontierPoints<-200
# Criando o objeto de restrições
constraints <- portfolioConstraints()
# Criando o objeto de restrições
constraints <- portfolioConstraints(data = data, spec = spec)
constarints
constraints
# Definindo a restrição de cardinalidade
ncardConstraints(constraints, min.card = 3, max.card = 5)
# Realizando a otimização do portfólio
opt_portfolio <- portfolioFrontier(data, spec, constraints = constraints)
fPortfolio::nCardConstraints(data = data, spec = spec, constraints = "LongOnly")
fPortfolio::minCardConstraints(data = data, spec = spec, constraints = "LongOnly")
# Define your portfolio assets and their returns
assets <- c("Asset1", "Asset2", "Asset3", "Asset4", "Asset5")  # Replace with your asset names
returns <- matrix(data = c(
# Replace with your asset returns (each column represents an asset)
# Format: Asset1, Asset2, Asset3, Asset4, Asset5
c(0.10, 0.12, 0.08, 0.15, 0.09),
c(0.07, 0.09, 0.05, 0.10, 0.06),
c(0.12, 0.14, 0.11, 0.13, 0.10),
c(0.09, 0.11, 0.07, 0.12, 0.08),
c(0.06, 0.08, 0.04, 0.09, 0.05)
), nrow = 5, ncol = 5, byrow = TRUE)
colnames(returns) <- assets
# Define your worst-case CVaR optimization problem
portfolio <- portfolioSpec(assets)
# Set the objective function as worst-case CVaR
setObjective(portfolio) <- "CVaR"
# Set the portfolio constraints
constraints <- c("FullInvestment", "Cardinality")
# Define the number of assets to include in the portfolio
cardinality <- 3  # Change this value to set the desired cardinality
# Set the maximum number of assets in the portfolio
setMaxCardinality(portfolio) <- cardinality
# Create the portfolio object
portfolio <- feasiblePortfolio(
portfolio,
data = as.timeSeries(returns),
constraints = constraints
)
# Define your worst-case CVaR optimization problem
portfolio <- portfolioSpec()
# Set the objective function as worst-case CVaR
setObjective(portfolio) <- "CVaR"
# Set the portfolio constraints
constraints <- c("FullInvestment", "Cardinality")
# Define the number of assets to include in the portfolio
cardinality <- 3  # Change this value to set the desired cardinality
# Set the maximum number of assets in the portfolio
setMaxCardinality(portfolio) <- cardinality
# Create the portfolio object
portfolio <- feasiblePortfolio(
portfolio,
data = as.timeSeries(returns),
constraints = constraints
)
# Optimize the portfolio
optimizedPortfolio <- solveRblpapi(portfolio)
# Print the optimized portfolio weights
print(optimizedPortfolio)
# Calculate the worst-case CVaR of the optimized portfolio
worstCaseCVaR <- portfolioCVaR(portfolio, optimizedPortfolio)
help("nCardConstraints")
help("Port-au-Prince")
help("portfolioConstraints")
minCardConstraints(data, spec=spec, constraints="LongOnly")
ncardConstraints(constraints, min.card = 3, max.card = 5)
fPortfolio::nCardConstraints(data = data, spec = spec, constraints = "LongOnly")
constraints
# Dados de retorno dos ativos
data <- as.timeSeries(returns)
# Definindo os parâmetros da otimização
nAssets <- ncol(data)
spec <- portfolioSpec()
fPortfolio::setType(spec) <- "CVaR"  # Set portfolio type as CVaR
fPortfolio::setSolver(spec) <- "solveRglpk.CVAR"  # Use linear programming solver for CVaR optimization
fPortfolio::setAlpha(spec) <- 0.025  # Set CVaR alpha level as 0.05 (CVaR_0.95)
fPortfolio::setTargetReturn(spec) <- targetReturn
# Criando o objeto de restrições
constraints <- portfolioConstraints(data = data, spec = spec)
constraints
# Importing data and calculating returns
returns <- tidyquant::tq_get(c("PETR4.SA", "VALE3.SA", "ITUB4.SA",
"BBAS3.SA", "ABEV3.SA", "BBDC4.SA",
"SLCE3.SA", "BBSE3.SA", "SMTO3.SA",
"AMER3.SA", "MGLU3.SA", "KLBN11.SA",
"ITSA4.SA", "BPAC11.SA", "SUZB3.SA",
"RENT3.SA", "LREN3.SA", "PETR3.SA",
"SANB11.SA", "B3SA3.SA", "YDUQ3.SA"),
from = "1997-01-01") %>%
dplyr::select(date, symbol, adjusted) %>%
dplyr::group_by(symbol) %>%
dplyr::mutate(return = log(adjusted) - log(dplyr::lag(adjusted))) %>%
dplyr::ungroup() %>%
dplyr::select(-adjusted) %>%
tidyr::spread(symbol, return) %>%
na.omit()
# Creating auxiliary matrices and list
N <- base::ncol(returns) - 1   # Number of assets
K <- 252                 # Window size for GARCH estimation
index_vector <- seq(1, nrow(returns), by = K)  # Index vector for rolling optimization
names_vector <- names(returns)[-1]   # Asset names for reference
portfolio_daily_returns <- matrix(nrow = nrow(returns), ncol = 1)  # Matrix to store portfolio returns
portfolio_daily_returns[1:K, ] <- 0  # Initialize the first K rows as zero
##### Setting up a fPortfolio min CVaR optimization
cvar_opt <- matrix(nrow = length(index_vector) - 1, ncol = N)  # Matrix to store CVaR optimization results
targetReturn <- 0  # Daily target return constraint
frontierSpec <- fPortfolio::portfolioSpec()  # Portfolio specification for optimization
fPortfolio::setType(frontierSpec) <- "CVaR"  # Set portfolio type as CVaR
fPortfolio::setSolver(frontierSpec) <- "solveRglpk.CVAR"  # Use linear programming solver for CVaR optimization
fPortfolio::setAlpha(frontierSpec) <- 0.025  # Set CVaR alpha level as 0.05 (CVaR_0.95)
fPortfolio::setTargetReturn(frontierSpec) <- targetReturn  # Set the daily target return constraint
# Dados de retorno dos ativos
data <- as.timeSeries(returns)
# Definindo os parâmetros da otimização
nAssets <- ncol(data)
spec <- portfolioSpec()
fPortfolio::setType(spec) <- "CVaR"  # Set portfolio type as CVaR
fPortfolio::setSolver(spec) <- "solveRglpk.CVAR"  # Use linear programming solver for CVaR optimization
fPortfolio::setAlpha(spec) <- 0.025  # Set CVaR alpha level as 0.05 (CVaR_0.95)
fPortfolio::setTargetReturn(spec) <- targetReturn
nCardConstraints(data, spec)
ncol(data)
minCardConstraints(data, spec)
cardinality <- c("minCard=5", "maxCard=8")
# Criando o objeto de restrições
constraints <- portfolioConstraints(data = data, spec = spec)
constraints
# Realizando a otimização do portfólio
opt_portfolio <- portfolioFrontier(data, spec, constraints = cardinality)
# Dados de retorno dos ativos
data <- as.timeSeries(returns)
# Definindo os parâmetros da otimização
nAssets <- ncol(data)
spec <- portfolioSpec()
fPortfolio::setType(spec) <- "CVaR"  # Set portfolio type as CVaR
fPortfolio::setSolver(spec) <- "solveRglpk.CVAR"  # Use linear programming solver for CVaR optimization
fPortfolio::setAlpha(spec) <- 0.025  # Set CVaR alpha level as 0.05 (CVaR_0.95)
fPortfolio::setTargetReturn(spec) <- targetReturn
cardinality <- c("minCard=5", "maxCard=8")
# Realizando a otimização do portfólio
opt_portfolio <- portfolioFrontier(data, spec, constraints = cardinality)
cardinality <- rep("minCard=5", nAssets)
# Realizando a otimização do portfólio
opt_portfolio <- portfolioFrontier(data, spec, constraints = cardinality)
# Extraindo os pesos dos ativos no portfólio otimizado
weights <- getWeights(opt_portfolio)
weights
constraints
help("setNFrontierPoints<-")
opt_portfolio
cardinality <- rep("maxCard=8", nAssets)
# Realizando a otimização do portfólio
opt_portfolio <- portfolioFrontier(data, spec, constraints = cardinality)
opt_portfolio
# Extraindo os pesos dos ativos no portfólio otimizado
weights <- getWeights(opt_portfolio)
# Visualizando a alocação de pesos
print(weights)
class(weights)
nrow(weights)
spec
# Realizando a otimização do portfólio
opt_portfolio <- portfolioFrontier(data, spec, constraints = "LongOnly")
# Extraindo os pesos dos ativos no portfólio otimizado
weights <- getWeights(opt_portfolio)
# Visualizando a alocação de pesos
print(weights)
cardinality <- rep("maxCard=5", "maxCard=8", nAssets)
cardinality
cardinality <- rep("minCard=5", "maxCard=8", nAssets)
cardinality
cardinality <- c(rep("minCard=5", nAssets),
rep("maxCard=8", nAssets))
cardinality
# Realizando a otimização do portfólio
opt_portfolio <- portfolioFrontier(data, spec, constraints = "LongOnly")
# Realizando a otimização do portfólio
opt_portfolio <- portfolioFrontier(data, spec, constraints = cardinality)
# Extraindo os pesos dos ativos no portfólio otimizado
weights <- fPortfolio::getWeights(opt_portfolio)
weights
i=1
i=2
j=1
# Matrix to save sigma forecasts
unif_dist <- garch_pred <- sigma <- residuals <- matrix(nrow = K, ncol = N)
garch_coef <- vector("list", length = N)
t1 <- index_vector[i - 1]
t2 <- index_vector[i] - 1
# Looping through each asset
for (j in 1:length(names_vector)) {
x <- cbind(returns[t1:t2, (j + 1)])
# Fitting GARCH model
garch_fit <- try(rugarch::ugarchfit(mod_garch, data = x, solver = "hybrid"),
silent = TRUE)
residuals[, j] <- garch_fit@fit$residuals
sigma[, j] <- garch_fit@fit$sigma
garch_coef[[j]] <- garch_fit@fit$coef
unif_dist[, j] <- fGarch::psstd(q = residuals[, j] / sigma[, j],
nu = garch_coef[[j]][6],
xi = garch_coef[[j]][5])
}
## Creating elliptical copula objects and estimating "initial guesses" for each copula parameter.
# Then, we maximize loglikelihood of the linear combination of the three copulas
par1 <- copula::fitCopula(copC, unif_dist, "itau", estimate.variance = TRUE)@estimate # Inversion of Kendall's tau for Clayton
j=16
##### Setting up a fPortfolio min CVaR optimization
cvar_opt <- matrix(nrow = length(index_vector) - 1, ncol = N)  # Matrix to store CVaR optimization results
targetReturn <- 0  # Daily target return constraint
frontierSpec <- fPortfolio::portfolioSpec()  # Portfolio specification for optimization
fPortfolio::setType(frontierSpec) <- "CVaR"  # Set portfolio type as CVaR
fPortfolio::setSolver(frontierSpec) <- "solveRglpk.CVAR"  # Use linear programming solver for CVaR optimization
fPortfolio::setAlpha(frontierSpec) <- 0.025  # Set CVaR alpha level as 0.05 (CVaR_0.95)
fPortfolio::setTargetReturn(frontierSpec) <- targetReturn  # Set the daily target return constraint
# Matrix to save sigma forecasts
unif_dist <- garch_pred <- sigma <- residuals <- matrix(nrow = K, ncol = N)
garch_coef <- vector("list", length = N)
t1 <- index_vector[i - 1]
t2 <- index_vector[i] - 1
# Looping through each asset
for (j in 1:length(names_vector)) {
x <- cbind(returns[t1:t2, (j + 1)])
# Fitting GARCH model
garch_fit <- try(rugarch::ugarchfit(mod_garch, data = x, solver = "hybrid"),
silent = TRUE)
residuals[, j] <- garch_fit@fit$residuals
sigma[, j] <- garch_fit@fit$sigma
garch_coef[[j]] <- garch_fit@fit$coef
unif_dist[, j] <- fGarch::psstd(q = residuals[, j] / sigma[, j],
nu = garch_coef[[j]][6],
xi = garch_coef[[j]][5])
}
## Creating elliptical copula objects and estimating "initial guesses" for each copula parameter.
# Then, we maximize loglikelihood of the linear combination of the three copulas
par1 <- copula::fitCopula(copC, unif_dist, "itau", estimate.variance = TRUE)@estimate # Inversion of Kendall's tau for Clayton
## Saving optimization parameters in a list
cop_param <- opt$pars
# Clayton, t, gumbel, and ctg variates matrix
ctg <- Cc <- Cg <- Ct <- matrix(nrow = K, ncol = N)
## Generating copula variates
Cc[, ] <- cop_param[5] * copula::rCopula(n = K,
copula = copula::claytonCopula(param = cop_param[1],
dim = N))
Cg[, ] <- cop_param[6] * copula::rCopula(n = K,
copula = copula::gumbelCopula(param = cop_param[2],
dim = N))
Ct[, ] <- cop_param[7] * copula::rCopula(n = K,
copula = copula::tCopula(param = cop_param[3],
df = cop_param[4],
dim = N))
# Linear combination of copula varieties
ctg <- Cc + Ct + Cg
# For each asset, generate copula 'z' dependence structure
rtn_pred <- mean_pred <- sigma_pred <- zsim <- matrix(nrow = K, ncol = N)
for (j in 1:N) {
zsim[, j] <- fGarch::qsstd(ctg[, j],
nu = garch_coef[[j]][6],
xi = garch_coef[[j]][5]) /
sd(fGarch::qsstd(ctg[, j], nu = garch_coef[[j]][6],
xi = garch_coef[[j]][5]))
rtn_t <- as.numeric(returns[(t2 - 1), (j + 1)])
sigma_t <- sigma[K, j]
sigma_pred[1, j] <- sqrt(garch_coef[[j]][7] +  # omega
garch_coef[[j]][3] * (rtn_t)^2 +  # alpha1
garch_coef[[j]][4] * (sigma_t)^2)  # beta1
mean_pred[1, j] <- garch_coef[[j]][1] + garch_coef[[j]][2] * rtn_t  # mu and ar1
rtn_pred[1, j] <- mean_pred[1, j] + sigma_pred[1, j] * zsim[1, j]
for (t in 2:K) {
sigma_pred[t, j] <- sqrt(garch_coef[[j]][7] +  # omega
garch_coef[[j]][3] * (rtn_pred[(t - 1), j])^2 +  # alpha1
garch_coef[[j]][4] * (sigma_pred[(t - 1), j])^2)  # beta1
mean_pred[t, j] <- garch_coef[[j]][1] + garch_coef[[j]][2] * rtn_pred[(t - 1), j]  # mu and ar1
rtn_pred[t, j] <- mean_pred[t, j] + sigma_pred[t, j] * zsim[t, j]
}
}
## Optimizing portfolio using K simulated returns for each asset, for optimization period i
returnfPort <- as.timeSeries(rtn_pred[, 1:N])
frontier1g <- fPortfolio::efficientPortfolio(data = returnfPort,
spec = frontierSpec,
constraints = cardinality)
frontier1g
cardinality <- c(rep("minCard=6", nAssets),
rep("maxCard=8", nAssets))
frontier1g <- fPortfolio::efficientPortfolio(data = returnfPort,
spec = frontierSpec,
constraints = cardinality)
cvar_opt[(i - 1), 1:N] <- fPortfolio::getWeights(frontier1g)  # Storing resulting weights
frontier1g
cardinality <- c(rep("minCard=8", nAssets),
rep("maxCard=12", nAssets))
## Optimizing portfolio using K simulated returns for each asset, for optimization period i
returnfPort <- as.timeSeries(rtn_pred[, 1:N])
frontier1g <- fPortfolio::efficientPortfolio(data = returnfPort,
spec = frontierSpec,
constraints = cardinality)
frontier1g
i
cvar_opt[(i - 1), 1:N] <- fPortfolio::getWeights(frontier1g)  # Storing resulting weights
cvar_opt
spec
frontierSpec
fPortfolio::portfolioConstraints(returnfPort, frontierSpec, constraints="LongOnly")
fPortfolio::portfolioConstraints(returnfPort, frontierSpec, constraints=constraints)
source("~/GitHub/PortfolioRiskOpt/PortfolioRiskOpt/Sketch.R", echo=TRUE)
returns <- read.csv("log_rtn.csv")
returns
# Creating auxiliary matrices and list
N <- base::ncol(returns) - 1   # Number of assets
K <- 252                 # Window size for GARCH estimation
index_vector <- seq(1, nrow(returns), by = K)  # Index vector for rolling optimization
names_vector <- names(returns)[-1]   # Asset names for reference
weights <- matrix(nrow = length(index_vector), ncol = N) # Create a matrix to store the weights for each asset in the portfolio
colnames(weights) <- names_vector # Set the column names of the weights matrix as the asset names
weights[1,] <-  0 # Initialize the first row of the weights matrix as all zeros
portfolio_returns <- matrix(nrow = nrow(returns), ncol = 1)  # Matrix to store portfolio returns
portfolio_returns[1:K, ] <- 0  # Initialize the first K rows as zero
i=2
# Establishing window interval in-sample
t1 <- index_vector[i - 1]
t2 <- index_vector[i] - 1
# Convert the in-sample returns data to a matrix format
ret_matrix_insample <- as.matrix(returns[t1:t2, -1])
# Create a logical vector indicating if each asset has sufficient data
assets_with_valid_returns <- colMeans(ret_matrix_insample[1:10,]) != 0
# Subset the returns matrix and asset names based on assets with sufficient data
ret_matrix_insample <- !colMeans(is.na(ret_matrix_insample[,]))
ret_matrix_insample
# Convert the in-sample returns data to a matrix format
ret_matrix_insample <- as.matrix(returns[t1:t2, -1])
# Create a logical vector indicating if each asset has sufficient data
assets_with_valid_returns <- !colMeans(is.na(ret_matrix_insample[,]))
# Subset the returns matrix and asset names based on assets with sufficient data
ret_matrix_insample <- ret_matrix_insample[, assets_with_valid_returns]
ret_matrix_insample
# Fit the GARCH model to the returns data
fit_garch <- FitGarch(returns = ret_matrix_insample)
# setting R project environment
my_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(my_dir)
# cleaning variables and graphs
rm(list=ls())
graphics.off()
# Load required packages
library(tidyverse)     # Data manipulation and visualization
library(tidyquant)     # Financial data analysis
library(rugarch)       # Univariate GARCH modeling
library(fGarch)        # Multivariate GARCH modeling
library(copula)        # Copula modeling
library(Rsolnp)        # Nonlinear optimization
library(fPortfolio)    # Portfolio optimization
library(PerformanceAnalytics) # Performance metrics
library(xts) # Time series object
# Importing modules
source("data_preprocessing.R")
source("garch_estimate.R")
source("copula_estimate.R")
source("portfolio_optimization.R")
source("performance_metrics.R")
returns <- read_csv("log_rtn.csv")
# Creating auxiliary matrices and list
N <- base::ncol(returns) - 1   # Number of assets
K <- 252                 # Window size for GARCH estimation
index_vector <- seq(1, nrow(returns), by = K)  # Index vector for rolling optimization
names_vector <- names(returns)[-1]   # Asset names for reference
weights <- matrix(nrow = length(index_vector), ncol = N) # Create a matrix to store the weights for each asset in the portfolio
colnames(weights) <- names_vector # Set the column names of the weights matrix as the asset names
weights[1,] <-  0 # Initialize the first row of the weights matrix as all zeros
portfolio_returns <- matrix(nrow = nrow(returns), ncol = 1)  # Matrix to store portfolio returns
portfolio_returns[1:K, ] <- 0  # Initialize the first K rows as zero
# Establishing window interval in-sample
t1 <- index_vector[i - 1]
t2 <- index_vector[i] - 1
i=2
# Establishing window interval in-sample
t1 <- index_vector[i - 1]
t2 <- index_vector[i] - 1
# Convert the in-sample returns data to a matrix format
ret_matrix_insample <- as.matrix(returns[t1:t2, -1])
# Create a logical vector indicating if each asset has sufficient data
assets_with_valid_returns <- !colMeans(is.na(ret_matrix_insample[,]))
# Subset the returns matrix and asset names based on assets with sufficient data
ret_matrix_insample <- ret_matrix_insample[, assets_with_valid_returns]
# Fit the GARCH model to the returns data
fit_garch <- FitGarch(returns = ret_matrix_insample)
# Optimize the mixture of copulas using the uniform distribution from the GARCH model
copulas_mixture <- OptMixtureCopulas(unif_dist = fit_garch$unif_dist)
# Negative log-likelihood function for estimating copula weights and parameters
LLCG <- function(params, U, copC, copG, copt){
# Set copula parameters
slot(copC, "parameters") <- params[1]    # Initial Clayton parameter
slot(copG, "parameters") <- params[2]    # Initial Gumbel parameter
slot(copt, "parameters") <- params[3:4]  # Initial t parameters (correlation and degrees of freedom)
# Set copula weights
pi1 <- params[5]  # Weight of Clayton copula
pi2 <- params[6]  # Weight of Gumbel copula
pi3 <- params[7]  # Weight of t copula
# Calculate the log-likelihood function to be optimized
opt <- log(pi1 * copula::dCopula(U, copC) +
pi2 * copula::dCopula(U, copG) +
pi3 * copula::dCopula(U, copt))
# Handle infinite values in the log-likelihood
if(any(is.infinite(opt))){
opt[which(is.infinite(opt))] <- 0
}
# Return the negative sum of the log-likelihood
-sum(opt)
}
# Constrain function to ensure sum(weights) = 1
eqfun <- function(params, U, copC, copG, copt){
z <- params[5] + params[6] + params[7]
return(z)
}
# Initialize copula objects
copt <- copula::tCopula(param = 0.5, dim = ncol(unif_dist))  # t-Copula with parameter 0.5
unif_dist = fit_garch$unif_dist
unif_dist
is.na(unif_dist)
# Initialize copula objects
copt <- copula::tCopula(param = 0.5, dim = ncol(unif_dist))  # t-Copula with parameter 0.5
copC <- copula::claytonCopula(2, dim = ncol(unif_dist))      # Clayton copula with delta = 2
copG <- copula::gumbelCopula(2, dim = ncol(unif_dist))       # Gumbel copula with theta = 2
# Define lower and upper bounds for the copula parameters and weights
lower <- c(0.1, 1, -0.9, (2 + .Machine$double.eps), 0, 0, 0)
upper <- c(copC@param.upbnd, copG@param.upbnd, 1, 100, 1, 1, 1)
## Creating elliptical copula objects and estimating "initial guesses" for each copula parameter.
# Then, we maximize loglikelihood of the linear combination of the three copulas
par1 <- copula::fitCopula(copC, unif_dist, "itau", estimate.variance = TRUE)@estimate # Inversion of Kendall's tau for Clayton
par2 <- copula::fitCopula(copG, unif_dist, "itau", estimate.variance = TRUE)@estimate # Inversion of Kendall's tau for Gumbel
par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE)@estimate # MPL to estimate Degrees of Freedom (DF)
sum(is.infinite(unif_dist))
sum(is.na(unif_dist))
par3 <- copula::fitCopula(copt, unif_dist, "ml", estimate.variance = FALSE)@estimate # MPL to estimate Degrees of Freedom (DF)
unif_dist = unif_dist[,1:100]
par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE)@estimate
unif_dist = unif_dist[,1:100]
copt <- copula::tCopula(param = 0.5, dim = ncol(unif_dist))
par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE)@estimate
unif_dist = unif_dist[,1:20]
copt <- copula::tCopula(param = 0.5, dim = ncol(unif_dist))
par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE)@estimate
unif_dist = unif_dist[,1:30]
copt <- copula::tCopula(param = 0.5, dim = ncol(unif_dist))
par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE)@estimate
unif_dist = unif_dist[,1:40]
copt <- copula::tCopula(param = 0.5, dim = ncol(unif_dist))
par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE)@estimate
unif_dist = fit_garch$unif_dist
unif_dist = unif_dist[,1:40]
copt <- copula::tCopula(param = 0.5, dim = ncol(unif_dist))
par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE)@estimate
unif_dist = unif_dist[,1:30]
copt <- copula::tCopula(param = 0.5, dim = ncol(unif_dist))
par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE)@estimate
unif_dist = unif_dist[,1:29]
copt <- copula::tCopula(param = 0.5, dim = ncol(unif_dist))
par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE)@estimate
unif_dist = unif_dist[,1:28]
copt <- copula::tCopula(param = 0.5, dim = ncol(unif_dist))
par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE)@estimate
returns[1,30]
unif_dist[,29]
unif_dist = fit_garch$unif_dist
unif_dist[,29]
unif_dist = unif_dist[,c(1:28,30)]
copt <- copula::tCopula(param = 0.5, dim = ncol(unif_dist))
par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE)@estimate
unif_dist = fit_garch$unif_dist
unif_dist = unif_dist[,1:29]
copt <- copula::tCopula(param = 0.7, dim = ncol(unif_dist))
par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE)@estimate
copt <- copula::tCopula(param = 0.8, dim = ncol(unif_dist))
par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE)@estimate
copt <- copula::tCopula(param = 0.2, dim = ncol(unif_dist))
par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE)@estimate
unif_dist = unif_dist[,1:28]
copt <- copula::tCopula(param = 0.2, dim = ncol(unif_dist))
par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE)@estimate
