"bit64",
"bitops",
"blob",
"blotters",
"brew",
"brio",
"broom",
"bslib",
"cachem",
"callr",
"carret",
"caTools",
"cellranger",
"checkmate",
"chron",
"cli",
"clipr",
"colorRamps",
"colorspace",
"commonmark",
"conflicted",
"carrplot",
"cpp11",
"crayon",
"credentials",
"crosstalk",
"curl",
"data.table",
"DBI",
"dbplyr",
"desc",
"devtools",
"dials",
"DiceDesign",
"diffobj",
"digest",
"DistributionUtils",
"doFuture",
"dplyr",
"dtplyr",
"e1071",
"egcm",
"ellipsis",
"entropy",
"epidisplay",
"evaluate",
"fansi",
"farver",
"fastlCA",
"fastmap",
"fBascis",
"fGarch",
"FinancialInstruments",
"FNN",
"fontawesome",
"forcats",
"foreach",
"forecast",
"formatR",
"fracdiff",
"fs",
"fUnitsRoots",
"funModdeling",
"furrr",
"future",
"future.apply",
"gargle",
"gbm",
"gdata",
"GeneralizedHyperbolic",
"generics",
"gert",
"GGally",
"ggplot2",
"ggThemeAssist",
"gh",
"gitcreds",
"globals",
"glue",
"gmodels",
"googledrive",
"googlesheets4",
"gower",
"GPfit",
"gplots",
"gridExtra",
"gss",
"gsubfn",
"gtable",
"gtools",
"hardhat",
"haven",
"highr",
"Hmisc",
"hms",
"htmlTable",
"htmlTools",
"htmlwidgets",
"httpuv",
"httr",
"ids",
"infer",
"ini",
"installr",
"ipred",
"isoband",
"ISWR",
"iterators",
"janitor",
"jpeg",
"jquerylib",
"jsonlite",
"kernlab",
"KFAS",
"knitr",
"ks",
"labeling",
"later",
"latticeExtra",
"lava",
"lazyeval",
"leaps",
"lhs",
"lifecycle",
"listenv",
"lmtest",
"locfit",
"lubridate",
"magrittr",
"markdown",
"MASS",
"mclust",
"memoise",
"mime",
"miniUI",
"mizc3D",
"MLeval",
"mnormt",
"modeldata",
"ModelMetrics",
"modelr",
"moments",
"MTS",
"multicool",
"munsell",
"mvtnorm",
"nloptr",
"normtest",
"numDeriv",
"openssl",
"openxlsx",
"padr",
"pander",
"parallely",
"parsnip",
"patchwork",
"PerformanceAnalytcs",
"pillar",
"pkgbuild",
"pkgconfig",
"pkgload",
"plot3D",
"plotly",
"plyr",
"pracma",
"praise",
"prettyunits",
"priceR",
"pROC",
"processx",
"prodlim",
"progress",
"progressr",
"promisses",
"proto",
"proxy",
"ps",
"psych",
"purrr",
"quadprog",
"Quandl",
"quantmod",
"quarks",
"R.cache",
"R.methodsS3",
"R.oo",
"R.rsp",
"R6",
"randomforest",
"rappdirs",
"rbcb",
"rcmdcheck",
"RColorBrewer",
"Rcpp",
"RcppArmadillio",
"RcppEigen",
"RcppRoll",
"readr",
"readxl",
"recipes",
"rematch",
"rematch2",
"remotes",
"repr",
"reprex",
"reshape",
"reshape2",
"riingo",
"riskR",
"rJava",
"rlang",
"rmarkdown",
"ROCR",
"rollRegress",
"roxygen2",
"rproojroot",
"rsample",
"Rsolnp",
"rstudioapi",
"rugarch",
"rversions",
"rvest",
"sandwich",
"sass",
"scales",
"scatterplott3D",
"selectr",
"sessioninfo",
"shiny",
"SkewHyperbolic",
"skimr",
"slider",
"smoots",
"snakecase",
"sourcetools",
"sp",
"spd",
"SQUAREM",
"stabledist",
"stringi",
"stringr",
"strucchenge",
"sys",
"testthat",
"tibble",
"tictoc",
"tidymodels",
"tidyquant",
"tidyr",
"tidyselect",
"tidyverse",
"timeDate",
"timeSeries",
"timetk",
"tinytex",
"tmvnsim",
"trunchorm",
"TSA",
"tseries",
"tsfeatures",
"TTR",
"tune",
"tzdb",
"urca",
"usethis",
"utf8",
"uuid",
"vars",
"vctrs",
"vip",
"viridis",
"viridisLite",
"visdat",
"vroom",
"vrtest",
"waldo",
"warp",
"whisker",
"withr",
"workflows",
"workflowsets",
"xfun",
"xlsx",
"xlsxjars",
"XML",
"xml2",
"xopen",
"xtable",
"xts",
"yaml",
"yardstick",
"zip",
"zoo")
for(i in 1:length(pacotes)){
install.packages(pacotes[i])
}
devtools::install_github("braverock/blotters")
devtools::install_github("braverock/blotter")
devtools::install_github("braverock/quantstrat")
install.package("reticulate")
x = 2
x = 2
y = 3
reticulate::repl_python()
x = 2
y = 3
print(x+y)
import pandas as pd
import pandas as pd
import numpy as np
import matplotlib as plt
import statsmodels as sm
df1 = pd.read_excel("ECONOMATICA/precos-bens-industriais.xlsx")
df1 = pd.read_excel("ECONOMATICA/precos-bens-industriais.xlsx")
head(df1)
pd.head(df1)
df1.head()
sheet_name = "VALE3")
sheet_name = "GOLL4")
df1 = pd.read_excel("ECONOMATICA/precos-bens-industriais.xlsx", sheet_name = "GOLL4")
df1.head()
df1 = pd.read_excel("ECONOMATICA/precos-bens-industriais.xlsx", sheet_name = ["GOLL4", "WEGE3"])
df1.head()
df1.head()
sheet_name = ["GOLL4", "WEGE3"])
df1 = pd.read_excel("ECONOMATICA/precos-bens-industriais.xlsx",
sheet_name = ["GOLL4", "WEGE3"])
df1.head()
View(df1)
df1[,1]
df1[1,]
df1
install.packages("rmarkdown")
install.packages("rmarkdown")
insatl.packages("tinytex")
insatll.packages("tinytex")
install.packages("tinytex")
install.packages("foo")
install.packages("pathtozip", repos = NULL)
.libPaths()
p
write.csv(unique(data.frame(installed.packages())[,1]),"packages.csv",row.names=F)
install.packages(as.character(read.csv("packages.csv")[,1]))
install.packages(as.character(read.csv("packages.csv")[, 1]))
install.packages(as.character(read.csv("packages.csv")[, 1]))
install.packages(as.character(read.csv("packages.csv")[, 1]))
install.packages(as.character(read.csv("packages.csv")[, 1]))
install.packages(as.character(read.csv("packages.csv")[,1]))
install.packages(as.character(read.csv("packages.csv")[, 1]))
install.packages("PerformanceAnalytics")
install.packages("PerformanceAnalytics")
install.packages("tabulizer")
install.packages("pdftools")
install.packages("rmarkdown")
library(tidyverse)
library(knitr)
library(kableExtra)
library(readxl)
library(pdftools)
library(rmarkdown)
library(tinytex)
knitr::opts_chunk$set(echo = FALSE)
pastas <- seq(from = 2, to = 50, by = 2)
lista <- map(pastas, .f = function(y){
read_excel("dados/lista-de-produtos.xlsx", sheet = y)})
caminhos <- c("dados/2022-06.xlsx",
"dados/2022-05.xlsx",
"dados/2022-04.xlsx",
"dados/2022-03.xlsx",
"dados/2022-02.xlsx",
"dados/2022-01.xlsx",
"dados/2021-12.xlsx",
"dados/2021-11.xlsx",
"dados/2021-10.xlsx",
"dados/2021-09.xlsx",
"dados/2021-08.xlsx",
"dados/2021-07.xlsx")
date <- c("2022-06-01", "2022-05-01", "2022-04-01",
"2022-03-01", "2022-02-01", "2022-01-01",
"2021-12-01", "2021-11-01", "2021-10-01",
"2021-09-01", "2021-08-01", "2021-07-01")
nomes <- NULL
demanda <- NULL
for(i in 1:length(caminhos)){
nomes[[i]] <- excel_sheets(caminhos[i])
demanda[[i]] <- map(nomes[[i]], .f = function(y){
read_excel(caminhos[i]) %>%
mutate(date = as.Date(date[i]))
})
}
dados <- NULL
for(i in 1:length(demanda)){
dados[[i]] <- demanda[[i]] %>%
bind_rows() %>%
mutate(valor = as.numeric(`Vl Liquido`)) %>%
select(date, Nome, valor) %>%
arrange(Nome) %>%
filter(Nome != lag(Nome))
}
base <- dados %>%
bind_rows() %>%
arrange(Nome, date) %>%
na.omit()
analise <- base %>%
group_by(date) %>%
summarise(soma = (sum(valor)*30)/100,
media = mean(valor)*10)
grafico1 <-  ggplot(analise) +
geom_bar(aes(x = date, y = soma),
stat = "identity", fill = "ForestGreen", color = "Black") +
geom_line(aes(x = date, y = media),
stat = "identity", color = "Orange", size = 2) +
theme_bw() +
labs(x = "Meses",
y = "Reais")
tabela <- summary(base$valor)
tabela
summary(base$valor*100)
library(tidyverse)
library(readxl)
PerformanceAnalytics::charts.PerformanceSummary
install.packages("languageserver")
install.packages("radian")
# setting R project environment
my_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(my_dir)
# cleaning variables and graphs
rm(list=ls())
graphics.off()
# Load required packages
library(tidyverse)     # Data manipulation and visualization
library(tidyquant)     # Financial data analysis
library(rugarch)       # Univariate GARCH modeling
library(fGarch)        # Multivariate GARCH modeling
library(copula)        # Copula modeling
library(Rsolnp)        # Nonlinear optimization
library(fPortfolio)    # Portfolio optimization
library(PerformanceAnalytics) # Performance metrics
library(xts) # Time series object
# Importing modules
source("data_preprocessing.R")
source("garch_estimate.R")
source("copula_estimate.R")
source("portfolio_optimization.R")
source("performance_metrics.R")
# Retrieve the stock returns for the given tickers and start date
#returns <- GetReturns(tickers = tickers, start_date = start_date)
#returns <- read_csv("data_directory/log_rtn.csv")
returns <- read_csv("data_directory/etfs_rtn.csv")
# Creating auxiliary matrices and list
N <- base::ncol(returns) - 1   # Number of assets
K <- 252                 # Window size for GARCH estimation
index_vector <- seq(1, nrow(returns), by = K)  # Index vector for rolling optimization
names_vector <- names(returns)[-1]   # Asset names for reference
weights <- matrix(nrow = length(index_vector), ncol = N) # Create a matrix to store the weights for each asset in the portfolio
colnames(weights) <- names_vector # Set the column names of the weights matrix as the asset names
weights[1,] <-  0 # Initialize the first row of the weights matrix as all zeros
portfolio_returns <- matrix(nrow = nrow(returns), ncol = 1)  # Matrix to store portfolio returns
portfolio_returns[1:K, ] <- 0  # Initialize the first K rows as zero
weights <- matrix(nrow = nrow(returns), ncol = N) # Create a matrix to store the weights for each asset in the portfolio
colnames(weights) <- names_vector # Set the column names of the weights matrix as the asset names
weights[1:K,] <-  0 # Initialize the first row of the weights matrix as all zeros
for (i in (K + 1):nrow(returns)){
print(paste(i - K, "of", nrow(returns) - K))
# Establishing window interval in-sample
t1 <- i - K
t2 <- i - 1
# Convert the in-sample returns data to a matrix format
ret_matrix_insample <- as.matrix(returns[t1:t2, -1])
# Create a logical vector indicating if each asset has sufficient data
assets_with_valid_returns <- !colMeans(is.na(ret_matrix_insample[,]))
# Subset the returns matrix and asset names based on assets with sufficient data
ret_matrix_insample <- ret_matrix_insample[, assets_with_valid_returns]
# Fit the GARCH model to the returns data
fit_garch <- FitGarch(returns = ret_matrix_insample)
# Optimize the mixture of copulas using the uniform distribution from the GARCH model
copulas_mixture <- try(OptMixtureCopulas(unif_dist = fit_garch$unif_dist), silent=TRUE)
# Compute simulated standardized residuals using the optimized copula mixture and GARCH coefficients
zsim <- ComputeZSim(copula_mixture = copulas_mixture, garch_coef = fit_garch$garch_coef)
# Predict future returns using the GARCH model, simulated residuals, and volatility estimates
ret_pred <- PredictGarch(returns = ret_matrix_insample,
sigma = fit_garch$sigma,
zsim = zsim,
garch_coef = fit_garch$garch_coef)
# Perform CVaR optimization to determine the optimal portfolio weights
weights[i, names_vector[assets_with_valid_returns]] <- CVaROptimization(returns = ret_pred)
weights[i, names_vector[!assets_with_valid_returns]] <- 0
# Convert the realized returns data to a matrix format
ret_matrix_outofsample <- as.matrix(returns[i, -1])
ret_matrix_outofsample[, names_vector[!assets_with_valid_returns]] <- 0
# Calculate the portfolio returns based on the optimal weights
portfolio_returns[i,] <- RetPortfolio(returns = ret_matrix_outofsample,
weights = rbind(weights[i,])) - 0.0003
}
portfolio_returns
# Convert the portfolio_returns matrix to an xts object
portfolio_returns_xts <- xts::xts(portfolio_returns, order.by = returns$date)
# Calculate Sharpe ratio
sharpe_ratio <- PerformanceAnalytics::SharpeRatio.annualized(portfolio_returns_xts)
# Calculate annualized return
annualized_return <- PerformanceAnalytics::Return.annualized(portfolio_returns_xts)
# Calculate cumulative return
cumulative_return <- PerformanceAnalytics::Return.cumulative(portfolio_returns_xts)
# Calculate drawdowns
drawdown <- PerformanceAnalytics::maxDrawdown(portfolio_returns_xts)
# Print the calculated metrics
print(sharpe_ratio)
print(annualized_return)
print(cumulative_return)
print(drawdown)
# Generate graph
PerformanceAnalytics::charts.PerformanceSummary(portfolio_returns_xts)
