names(Symbols) <- Update
Symbols
# Filtering stocks on Ibovespa and splitting  data set
Ret_inSample <- map(Update, .f = function(x){
Ret %>%
select(date,  Symbols[[paste(x)]]) %>% # filter Ibov stocks
dplyr::filter(date > as.Date(x) - 365, # split data in in-sample
date <= as.Date(x)) %>%
select(-date) %>%
as.matrix()
})
names(Ret_inSample) <- Update
Ret_inSample
# Filtering stocks on Ibovespa and splitting  data set
Ret_inSample <- map(Update, .f = function(x){
Ret %>%
select(date,  Symbols[[paste(x)]]) %>% # filter Ibov stocks
dplyr::filter(date > as.Date(x) - 365, # split data in in-sample
date <= as.Date(x)) %>%
select(-date) %>% # exclude date column
as.matrix() # convert to matrix format
})
names(Ret_inSample) <- Update
Ret_inSample
Ret_outofSample <- map(Update, .f = function(x){
Ret %>%
select(date,  Symbols[[paste(x)]]) %>% # filter Ibov stocks
dplyr::filter(date > as.Date(x), # split data in out-of-sample
date <= as.Date(x) + 365) %>%
select(-date) %>% # exclude date column
as.matrix() # convert to matrix format
})
names(Ret_outofSample) <- Update + 365
Ret_outofSample
# Initialize the GARCH specification
mod_garch <- try(rugarch::ugarchspec(variance.model = list(model = "sGARCH",
garchOrder = c(1, 1),
variance.targeting = TRUE),
mean.model = list(armaOrder = c(1, 0)),
distribution.model = "sstd"),
silent = TRUE)
# Matrix to save model coefficients, standard deviation and residuals
unif_dist <- garch_pred <- sigma <- residuals <- matrix(nrow = nrow(returns),
ncol = ncol(returns))
garch_coef <- vector("list", length = ncol(returns))
nrow(Ret_inSample$`1997-12-31`)
Ret_inSample[["1997-12-31"]]
# Create returns matrix
returns <- Ret_inSample[["1997-12-31"]]
# Matrix to save model coefficients, standard deviation and residuals
unif_dist <- garch_pred <- sigma <- residuals <- matrix(nrow = nrow(returns),
ncol = ncol(returns))
garch_coef <- vector("list", length = ncol(returns))
# Loop over each asset
for(j in 1:ncol(returns)){
# Fitting GARCH model
garch_fit <- try(ugarchfit(mod_garch, data = returns[,j], solver = "hybrid"),
silent=TRUE)
# Save residuals, sigma forecasts, GARCH coefficients, and uniform distribution values
residuals[, j] <- garch_fit@fit$residuals
sigma[, j] <- garch_fit@fit$sigma
garch_coef[[j]] <- garch_fit@fit$coef
unif_dist[, j] <- fGarch::psstd(q = residuals[, j] / sigma[, j],
nu = garch_coef[[j]][6],
xi = garch_coef[[j]][5])
}
# Loop over each asset
for(j in 1:ncol(returns)){
# Fitting GARCH model
print(j)
garch_fit <- try(ugarchfit(mod_garch, data = returns[,j], solver = "hybrid"),
silent=TRUE)
# Save residuals, sigma forecasts, GARCH coefficients, and uniform distribution values
residuals[, j] <- garch_fit@fit$residuals
sigma[, j] <- garch_fit@fit$sigma
garch_coef[[j]] <- garch_fit@fit$coef
unif_dist[, j] <- fGarch::psstd(q = residuals[, j] / sigma[, j],
nu = garch_coef[[j]][6],
xi = garch_coef[[j]][5])
}
# Create a logical vector indicating if each asset has sufficient data
assets_with_valid_returns <- !colMeans(is.na(returns))
# Subset the returns matrix and asset names based on assets with sufficient data
returns <- returns[, assets_with_valid_returns]
returns
# Matrix to save model coefficients, standard deviation and residuals
unif_dist <- garch_pred <- sigma <- residuals <- matrix(nrow = nrow(returns),
ncol = ncol(returns))
garch_coef <- vector("list", length = ncol(returns))
# Loop over each asset
for(j in 1:ncol(returns)){
# Fitting GARCH model
print(j)
garch_fit <- try(ugarchfit(mod_garch, data = returns[,j], solver = "hybrid"),
silent=TRUE)
# Save residuals, sigma forecasts, GARCH coefficients, and uniform distribution values
residuals[, j] <- garch_fit@fit$residuals
sigma[, j] <- garch_fit@fit$sigma
garch_coef[[j]] <- garch_fit@fit$coef
unif_dist[, j] <- fGarch::psstd(q = residuals[, j] / sigma[, j],
nu = garch_coef[[j]][6],
xi = garch_coef[[j]][5])
}
returns[,29]
returns[[29]]
returns[, c(28, 29)]
# Create returns matrix
returns <- Ret_inSample[["1997-12-31"]]
# Matrix to save model coefficients, standard deviation and residuals
unif_dist <- garch_pred <- sigma <- residuals <- matrix(nrow = nrow(returns),
ncol = ncol(returns))
garch_coef <- vector("list", length = ncol(returns))
# Loop over each asset
for(j in 1:ncol(returns)){
# Fitting GARCH model
print(j)
garch_fit <- try(ugarchfit(mod_garch, data = returns[,j], solver = "hybrid"),
silent=TRUE)
# Save residuals, sigma forecasts, GARCH coefficients, and uniform distribution values
residuals[, j] <- garch_fit@fit$residuals
sigma[, j] <- garch_fit@fit$sigma
garch_coef[[j]] <- garch_fit@fit$coef
unif_dist[, j] <- fGarch::psstd(q = residuals[, j] / sigma[, j],
nu = garch_coef[[j]][6],
xi = garch_coef[[j]][5])
}
# Loop over each asset
for(j in 1:ncol(returns)){
# Fitting GARCH model
print(j)
garch_fit <- try(ugarchfit(mod_garch, data = returns[,j], solver = "hybrid"),
silent=TRUE)
# Check if garch_fit is an error or a successful fit
if (inherits(garch_fit, "try-error")) {
# Handle the error (e.g., print an error message)
cat("Error in fitting GARCH model for asset", j, "\n")
} else {
# Save residuals, sigma, GARCH coefficients, and uniform distribution values
residuals[, j] <- garch_fit@fit$residuals
sigma[, j] <- garch_fit@fit$sigma
garch_coef[[j]] <- garch_fit@fit$coef
unif_dist[, j] <- fGarch::psstd(q = residuals[, j] / sigma[, j],
nu = garch_coef[[j]][6],
xi = garch_coef[[j]][5])
}
}
unif_dist
LLCG <- function(params, U, copC, copG, copt){
# LLCG: Negative log-likelihood function for estimating copula weights and parameters.
# Inputs:
#   params: A numeric vector containing the initial values for copula parameters and weights.
#   U: A matrix containing the uniform (0 to 1) marginals of the data for each copula.
#   copC: A copula object (Clayton copula) with initial parameters to be estimated.
#   copG: A copula object (Gumbel copula) with initial parameters to be estimated.
#   copt: A copula object (t copula) with initial parameters to be estimated.
# Output:
#   The negative log-likelihood value to be optimized for estimating copula parameters and weights.
# Set copula parameters
slot(copC, "parameters") <- params[1]    # Initial Clayton parameter
slot(copG, "parameters") <- params[2]    # Initial Gumbel parameter
slot(copt, "parameters") <- params[3:4]  # Initial t parameters (correlation and degrees of freedom)
# Set copula weights
pi1 <- params[5]  # Weight of Clayton copula
pi2 <- params[6]  # Weight of Gumbel copula
pi3 <- params[7]  # Weight of t copula
# Calculate the log-likelihood function to be optimized
opt <- log(pi1 * copula::dCopula(U, copC) +
pi2 * copula::dCopula(U, copG) +
pi3 * copula::dCopula(U, copt))
# Handle infinite values in the log-likelihood
if(any(is.infinite(opt))){
opt[which(is.infinite(opt))] <- 0
}
# Return the negative sum of the log-likelihood
-sum(opt)
}
eqfun <- function(params, U, copC, copG, copt){
# eqfun: Constrain function to ensure sum of weights = 1.
# Inputs:
#   params: A numeric vector containing the values of copula weights to be constrained.
#   U: A matrix containing the uniform (0 to 1) marginals of the data for each copula.
#   copC: A copula object (Clayton copula) used in the likelihood function.
#   copG: A copula object (Gumbel copula) used in the likelihood function.
#   copt: A copula object (t copula) used in the likelihood function.
# Output:
#   The sum of the copula weights (pi1, pi2, pi3) to be constrained.
z <- params[5] + params[6] + params[7]
return(z)
}
# Initialize copula objects
copt <- copula::tCopula(param = 0.5, dim = ncol(unif_dist))  # t-Copula with parameter 0.5
copC <- copula::claytonCopula(2, dim = ncol(unif_dist))      # Clayton copula with delta = 2
copG <- copula::gumbelCopula(2, dim = ncol(unif_dist))       # Gumbel copula with theta = 2
# Define lower and upper bounds for the copula parameters and weights
lower <- c(0.1, 1, -0.9, (2 + .Machine$double.eps), 0, 0, 0)
upper <- c(copC@param.upbnd, copG@param.upbnd, 1, 100, 1, 1, 1)
## Creating elliptical copula objects and estimating "initial guesses" for each copula parameter.
# Then, we maximize loglikelihood of the linear combination of the three copulas
par1 <- copula::fitCopula(copC, unif_dist, "itau", estimate.variance = TRUE)@estimate # Inversion of Kendall's tau for Clayton
unif_dist
# Drop columns with NA values from unif_dist
unif_dist <- unif_dist[, complete.cases(unif_dist)]
# Identify columns with complete cases
complete_columns <- apply(unif_dist, 2, function(x) all(!is.na(x)))
# Subset the matrix to keep only columns with complete cases
unif_dist <- unif_dist[, complete_columns]
unif_dist
colnames(unif_dist) <- names(returns)
# Create returns matrix
returns <- Ret_inSample[["1997-12-31"]]
# Matrix to save model coefficients, standard deviation and residuals
unif_dist <- garch_pred <- sigma <- residuals <- matrix(nrow = nrow(returns),
ncol = ncol(returns))
garch_coef <- vector("list", length = ncol(returns))
# Rename columns
colnames(unif_dist) <- names(returns)
colnames(garch_pred) <- names(returns)
colnames(sigma) <- names(returns)
colnames(residuals) <- names(returns)
# Loop over each asset
for(j in 1:ncol(returns)){
# Fitting GARCH model
print(j)
garch_fit <- try(ugarchfit(mod_garch, data = returns[,j], solver = "hybrid"),
silent=TRUE)
# Check if garch_fit is an error or a successful fit
if (inherits(garch_fit, "try-error")) {
# Handle the error (e.g., print an error message)
cat("Error in fitting GARCH model for asset", j, "\n")
} else {
# Save residuals, sigma, GARCH coefficients, and uniform distribution values
residuals[, j] <- garch_fit@fit$residuals
sigma[, j] <- garch_fit@fit$sigma
garch_coef[[j]] <- garch_fit@fit$coef
unif_dist[, j] <- fGarch::psstd(q = residuals[, j] / sigma[, j],
nu = garch_coef[[j]][6],
xi = garch_coef[[j]][5])
}
}
# Create returns matrix
returns <- Ret_inSample[["1997-12-31"]]
# Matrix to save model coefficients, standard deviation and residuals
unif_dist <- garch_pred <- sigma <- residuals <- matrix(nrow = nrow(returns),
ncol = ncol(returns))
garch_coef <- vector("list", length = ncol(returns))
colnames(unif_dist) <- names(returns)
colnames(garch_pred) <- names(returns)
colnames(sigma) <- names(returns)
colnames(residuals) <- names(returns)
names(garch_coef) <- names(returns)
# Loop over each asset
for(j in 1:ncol(returns)){
# Fitting GARCH model
print(j)
garch_fit <- try(ugarchfit(mod_garch, data = returns[,j], solver = "hybrid"),
silent=TRUE)
# Check if garch_fit is an error or a successful fit
if (inherits(garch_fit, "try-error")) {
# Handle the error (e.g., print an error message)
cat("Error in fitting GARCH model for asset", j, "\n")
} else {
# Save residuals, sigma, GARCH coefficients, and uniform distribution values
residuals[, j] <- garch_fit@fit$residuals
sigma[, j] <- garch_fit@fit$sigma
garch_coef[[j]] <- garch_fit@fit$coef
unif_dist[, j] <- fGarch::psstd(q = residuals[, j] / sigma[, j],
nu = garch_coef[[j]][6],
xi = garch_coef[[j]][5])
}
}
LLCG <- function(params, U, copC, copG, copt){
# LLCG: Negative log-likelihood function for estimating copula weights and parameters.
# Inputs:
#   params: A numeric vector containing the initial values for copula parameters and weights.
#   U: A matrix containing the uniform (0 to 1) marginals of the data for each copula.
#   copC: A copula object (Clayton copula) with initial parameters to be estimated.
#   copG: A copula object (Gumbel copula) with initial parameters to be estimated.
#   copt: A copula object (t copula) with initial parameters to be estimated.
# Output:
#   The negative log-likelihood value to be optimized for estimating copula parameters and weights.
# Set copula parameters
slot(copC, "parameters") <- params[1]    # Initial Clayton parameter
slot(copG, "parameters") <- params[2]    # Initial Gumbel parameter
slot(copt, "parameters") <- params[3:4]  # Initial t parameters (correlation and degrees of freedom)
# Set copula weights
pi1 <- params[5]  # Weight of Clayton copula
pi2 <- params[6]  # Weight of Gumbel copula
pi3 <- params[7]  # Weight of t copula
# Calculate the log-likelihood function to be optimized
opt <- log(pi1 * copula::dCopula(U, copC) +
pi2 * copula::dCopula(U, copG) +
pi3 * copula::dCopula(U, copt))
# Handle infinite values in the log-likelihood
if(any(is.infinite(opt))){
opt[which(is.infinite(opt))] <- 0
}
# Return the negative sum of the log-likelihood
-sum(opt)
}
eqfun <- function(params, U, copC, copG, copt){
# eqfun: Constrain function to ensure sum of weights = 1.
# Inputs:
#   params: A numeric vector containing the values of copula weights to be constrained.
#   U: A matrix containing the uniform (0 to 1) marginals of the data for each copula.
#   copC: A copula object (Clayton copula) used in the likelihood function.
#   copG: A copula object (Gumbel copula) used in the likelihood function.
#   copt: A copula object (t copula) used in the likelihood function.
# Output:
#   The sum of the copula weights (pi1, pi2, pi3) to be constrained.
z <- params[5] + params[6] + params[7]
return(z)
}
# Initialize copula objects
copt <- copula::tCopula(param = 0.5, dim = ncol(unif_dist))  # t-Copula with parameter 0.5
copC <- copula::claytonCopula(2, dim = ncol(unif_dist))      # Clayton copula with delta = 2
copG <- copula::gumbelCopula(2, dim = ncol(unif_dist))       # Gumbel copula with theta = 2
# Define lower and upper bounds for the copula parameters and weights
lower <- c(0.1, 1, -0.9, (2 + .Machine$double.eps), 0, 0, 0)
upper <- c(copC@param.upbnd, copG@param.upbnd, 1, 100, 1, 1, 1)
# Identify columns with complete cases
complete_columns <- apply(unif_dist, 2, function(x) all(!is.na(x)))
# Subset the matrix to keep only columns with complete cases
unif_dist <- unif_dist[, complete_columns] # drop na columns
unif_dist
# Rename columns
colnames(unif_dist) <- names(returns)
colnames(garch_pred) <- names(returns)
colnames(sigma) <- names(returns)
colnames(residuals) <- names(returns)
names(garch_coef) <- names(returns)
unif_dist
names(returns)
# Create returns matrix
returns <- Ret_inSample[["1997-12-31"]]
# Matrix to save model coefficients, standard deviation and residuals
unif_dist <- garch_pred <- sigma <- residuals <- matrix(nrow = nrow(returns),
ncol = ncol(returns))
garch_coef <- vector("list", length = ncol(returns))
colnames(unif_dist) <- colnames(returns)
colnames(garch_pred) <- colnames(returns)
colnames(sigma) <- colnames(returns)
colnames(residuals) <- colnames(returns)
names(garch_coef) <- colnames(returns)
# Loop over each asset
for(j in 1:ncol(returns)){
# Fitting GARCH model
print(j)
garch_fit <- try(ugarchfit(mod_garch, data = returns[,j], solver = "hybrid"),
silent=TRUE)
# Check if garch_fit is an error or a successful fit
if (inherits(garch_fit, "try-error")) {
# Handle the error (e.g., print an error message)
cat("Error in fitting GARCH model for asset", j, "\n")
} else {
# Save residuals, sigma, GARCH coefficients, and uniform distribution values
residuals[, j] <- garch_fit@fit$residuals
sigma[, j] <- garch_fit@fit$sigma
garch_coef[[j]] <- garch_fit@fit$coef
unif_dist[, j] <- fGarch::psstd(q = residuals[, j] / sigma[, j],
nu = garch_coef[[j]][6],
xi = garch_coef[[j]][5])
}
}
unif_dist
# Initialize copula objects
copt <- copula::tCopula(param = 0.5, dim = ncol(unif_dist))  # t-Copula with parameter 0.5
copC <- copula::claytonCopula(2, dim = ncol(unif_dist))      # Clayton copula with delta = 2
copG <- copula::gumbelCopula(2, dim = ncol(unif_dist))       # Gumbel copula with theta = 2
# Define lower and upper bounds for the copula parameters and weights
lower <- c(0.1, 1, -0.9, (2 + .Machine$double.eps), 0, 0, 0)
upper <- c(copC@param.upbnd, copG@param.upbnd, 1, 100, 1, 1, 1)
# Identify columns with complete cases
complete_columns <- apply(unif_dist, 2, function(x) all(!is.na(x)))
# Subset the matrix to keep only columns with complete cases
unif_dist <- unif_dist[, complete_columns] # drop na columns
## Creating elliptical copula objects and estimating "initial guesses" for each copula parameter.
# Then, we maximize loglikelihood of the linear combination of the three copulas
par1 <- copula::fitCopula(copC, unif_dist, "itau", estimate.variance = TRUE)@estimate # Inversion of Kendall's tau for Clayton
tail(unif_dist)
## Creating elliptical copula objects and estimating "initial guesses" for each copula parameter.
# Then, we maximize loglikelihood of the linear combination of the three copulas
par1 <- copula::fitCopula(copC, unif_dist, "itau", estimate.variance = TRUE)@estimate # Inversion of Kendall's tau for Clayton
# Identify columns with complete cases
complete_columns <- apply(unif_dist, 2, function(x) all(!is.na(x)))
# Subset the matrix to keep only columns with complete cases
unif_dist <- unif_dist[, complete_columns] # drop na columns
# Initialize copula objects
copt <- copula::tCopula(param = 0.5, dim = ncol(unif_dist))  # t-Copula with parameter 0.5
copC <- copula::claytonCopula(2, dim = ncol(unif_dist))      # Clayton copula with delta = 2
copG <- copula::gumbelCopula(2, dim = ncol(unif_dist))       # Gumbel copula with theta = 2
# Define lower and upper bounds for the copula parameters and weights
lower <- c(0.1, 1, -0.9, (2 + .Machine$double.eps), 0, 0, 0)
upper <- c(copC@param.upbnd, copG@param.upbnd, 1, 100, 1, 1, 1)
## Creating elliptical copula objects and estimating "initial guesses" for each copula parameter.
# Then, we maximize loglikelihood of the linear combination of the three copulas
par1 <- copula::fitCopula(copC, unif_dist, "itau", estimate.variance = TRUE)@estimate # Inversion of Kendall's tau for Clayton
par2 <- copula::fitCopula(copG, unif_dist, "itau", estimate.variance = TRUE)@estimate # Inversion of Kendall's tau for Gumbel
par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE)@estimate # MPL to estimate Degrees of Freedom (DF)
any(is.na(unif_dist))
par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE, method = "Nelder-Mead")@estimate
par3 <- copula::fitCopula(copt, unif_dist, "ml", estimate.variance = FALSE)@estimate # MPL to estimate Degrees of Freedom (DF)
par3 <- copula::fitCopula(copt, unif_dist, "itau.mpl", estimate.variance = FALSE)@estimate # MPL to estimate Degrees of Freedom (DF)
unif_dist <- unif_dist[, 1:30]
# Initialize copula objects
copt <- copula::tCopula(param = 0.5, dim = ncol(unif_dist))  # t-Copula with parameter 0.5
copC <- copula::claytonCopula(2, dim = ncol(unif_dist))      # Clayton copula with delta = 2
copG <- copula::gumbelCopula(2, dim = ncol(unif_dist))       # Gumbel copula with theta = 2
# Define lower and upper bounds for the copula parameters and weights
lower <- c(0.1, 1, -0.9, (2 + .Machine$double.eps), 0, 0, 0)
upper <- c(copC@param.upbnd, copG@param.upbnd, 1, 100, 1, 1, 1)
## Creating elliptical copula objects and estimating "initial guesses" for each copula parameter.
# Then, we maximize loglikelihood of the linear combination of the three copulas
par1 <- copula::fitCopula(copC, unif_dist, "itau", estimate.variance = TRUE)@estimate # Inversion of Kendall's tau for Clayton
par2 <- copula::fitCopula(copG, unif_dist, "itau", estimate.variance = TRUE)@estimate # Inversion of Kendall's tau for Gumbel
par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE)@estimate # MPL to estimate Degrees of Freedom (DF)
unif_dist <- unif_dist[, 1:33]
# Initialize copula objects
copt <- copula::tCopula(param = 0.5, dim = ncol(unif_dist))  # t-Copula with parameter 0.5
copC <- copula::claytonCopula(2, dim = ncol(unif_dist))      # Clayton copula with delta = 2
copG <- copula::gumbelCopula(2, dim = ncol(unif_dist))       # Gumbel copula with theta = 2
# Subset the matrix to keep only columns with complete cases
unif_dist <- unif_dist[, complete_columns] # drop na columns
# Create returns matrix
returns <- Ret_inSample[["1997-12-31"]]
# Matrix to save model coefficients, standard deviation and residuals
unif_dist <- garch_pred <- sigma <- residuals <- matrix(nrow = nrow(returns),
ncol = ncol(returns))
garch_coef <- vector("list", length = ncol(returns))
colnames(unif_dist) <- colnames(returns)
colnames(garch_pred) <- colnames(returns)
colnames(sigma) <- colnames(returns)
colnames(residuals) <- colnames(returns)
names(garch_coef) <- colnames(returns)
# Loop over each asset
for(j in 1:ncol(returns)){
# Fitting GARCH model
print(j)
garch_fit <- try(ugarchfit(mod_garch, data = returns[,j], solver = "hybrid"),
silent=TRUE)
# Check if garch_fit is an error or a successful fit
if (inherits(garch_fit, "try-error")) {
# Handle the error (e.g., print an error message)
cat("Error in fitting GARCH model for asset", j, "\n")
} else {
# Save residuals, sigma, GARCH coefficients, and uniform distribution values
residuals[, j] <- garch_fit@fit$residuals
sigma[, j] <- garch_fit@fit$sigma
garch_coef[[j]] <- garch_fit@fit$coef
unif_dist[, j] <- fGarch::psstd(q = residuals[, j] / sigma[, j],
nu = garch_coef[[j]][6],
xi = garch_coef[[j]][5])
}
}
LLCG <- function(params, U, copC, copG, copt){
# LLCG: Negative log-likelihood function for estimating copula weights and parameters.
# Inputs:
#   params: A numeric vector containing the initial values for copula parameters and weights.
#   U: A matrix containing the uniform (0 to 1) marginals of the data for each copula.
#   copC: A copula object (Clayton copula) with initial parameters to be estimated.
#   copG: A copula object (Gumbel copula) with initial parameters to be estimated.
#   copt: A copula object (t copula) with initial parameters to be estimated.
# Output:
#   The negative log-likelihood value to be optimized for estimating copula parameters and weights.
# Set copula parameters
slot(copC, "parameters") <- params[1]    # Initial Clayton parameter
slot(copG, "parameters") <- params[2]    # Initial Gumbel parameter
slot(copt, "parameters") <- params[3:4]  # Initial t parameters (correlation and degrees of freedom)
# Set copula weights
pi1 <- params[5]  # Weight of Clayton copula
pi2 <- params[6]  # Weight of Gumbel copula
pi3 <- params[7]  # Weight of t copula
# Calculate the log-likelihood function to be optimized
opt <- log(pi1 * copula::dCopula(U, copC) +
pi2 * copula::dCopula(U, copG) +
pi3 * copula::dCopula(U, copt))
# Handle infinite values in the log-likelihood
if(any(is.infinite(opt))){
opt[which(is.infinite(opt))] <- 0
}
# Return the negative sum of the log-likelihood
-sum(opt)
}
eqfun <- function(params, U, copC, copG, copt){
# eqfun: Constrain function to ensure sum of weights = 1.
# Inputs:
#   params: A numeric vector containing the values of copula weights to be constrained.
#   U: A matrix containing the uniform (0 to 1) marginals of the data for each copula.
#   copC: A copula object (Clayton copula) used in the likelihood function.
#   copG: A copula object (Gumbel copula) used in the likelihood function.
#   copt: A copula object (t copula) used in the likelihood function.
# Output:
#   The sum of the copula weights (pi1, pi2, pi3) to be constrained.
z <- params[5] + params[6] + params[7]
return(z)
}
# Identify columns with complete cases
complete_columns <- apply(unif_dist, 2, function(x) all(!is.na(x)))
# Subset the matrix to keep only columns with complete cases
unif_dist <- unif_dist[, complete_columns] # drop na columns
unif_dist <- unif_dist[, 1:33]
# Initialize copula objects
copt <- copula::tCopula(param = 0.5, dim = ncol(unif_dist))  # t-Copula with parameter 0.5
copC <- copula::claytonCopula(2, dim = ncol(unif_dist))      # Clayton copula with delta = 2
copG <- copula::gumbelCopula(2, dim = ncol(unif_dist))       # Gumbel copula with theta = 2
# Define lower and upper bounds for the copula parameters and weights
lower <- c(0.1, 1, -0.9, (2 + .Machine$double.eps), 0, 0, 0)
upper <- c(copC@param.upbnd, copG@param.upbnd, 1, 100, 1, 1, 1)
## Creating elliptical copula objects and estimating "initial guesses" for each copula parameter.
# Then, we maximize loglikelihood of the linear combination of the three copulas
par1 <- copula::fitCopula(copC, unif_dist, "itau", estimate.variance = TRUE)@estimate # Inversion of Kendall's tau for Clayton
par2 <- copula::fitCopula(copG, unif_dist, "itau", estimate.variance = TRUE)@estimate # Inversion of Kendall's tau for Gumbel
par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE)@estimate # MPL to estimate Degrees of Freedom (DF)
