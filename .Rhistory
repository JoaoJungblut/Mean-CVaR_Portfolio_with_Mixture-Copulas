zsim = zsim,
garch_coef = garch_coef)
ret_pred <- as.data.frame(ret_pred)
colnames(ret_pred) <- colnames(returns)
# Perform CVaR optimization to determine the optimal portfolio weights
weights <- rep(0, ncol(returns))
names(weights) <- colnames(returns)
weights <- CVaROptimization(returns = ret_pred,
Alpha = 0.05,
TargetReturn = 0.03,
NumAssets = 16)
# Calculate portfolio returns based on the optimal weights
ret_matrix_outofsample <- Ret_outofSample$`2022-12-31`[,colnames(returns)]
portfolio_returns <- ret_matrix_outofsample  %*%  weights
# Calculate cumulative returns
cumulative_returns <- cumprod(1 + portfolio_returns) - 1
# Plot the cumulative returns
plot(cumulative_returns, type = "l", col = "green", lwd = 2,
main = "Portfolio Performance",
xlab = "Time Period", ylab = "Cumulative Returns")
cumulative_returns
# Perform CVaR optimization to determine the optimal portfolio weights
weights <- rep(0, ncol(returns))
names(weights) <- colnames(returns)
weights <- CVaROptimization(returns = ret_pred,
Alpha = 0.05,
TargetReturn = 0.01,
NumAssets = 16)
# Calculate portfolio returns based on the optimal weights
ret_matrix_outofsample <- Ret_outofSample$`2022-12-31`[,colnames(returns)]
portfolio_returns <- ret_matrix_outofsample  %*%  weights
# Calculate cumulative returns
cumulative_returns <- cumprod(1 + portfolio_returns) - 1
# Plot the cumulative returns
plot(cumulative_returns, type = "l", col = "green", lwd = 2,
main = "Portfolio Performance",
xlab = "Time Period", ylab = "Cumulative Returns")
weights <- CVaROptimization(returns = ret_pred,
Alpha = 0.05,
TargetReturn = 0.005,
NumAssets = 16)
# Perform CVaR optimization to determine the optimal portfolio weights
weights <- rep(0, ncol(returns))
names(weights) <- colnames(returns)
weights <- CVaROptimization(returns = ret_pred,
Alpha = 0.05,
TargetReturn = 0.005,
NumAssets = 16)
# Calculate portfolio returns based on the optimal weights
ret_matrix_outofsample <- Ret_outofSample$`2022-12-31`[,colnames(returns)]
portfolio_returns <- ret_matrix_outofsample  %*%  weights
# Calculate cumulative returns
cumulative_returns <- cumprod(1 + portfolio_returns) - 1
# Plot the cumulative returns
plot(cumulative_returns, type = "l", col = "green", lwd = 2,
main = "Portfolio Performance",
xlab = "Time Period", ylab = "Cumulative Returns")
weights <- CVaROptimization(returns = ret_pred,
Alpha = 0.05,
TargetReturn = 0,
NumAssets = 16)
# Calculate portfolio returns based on the optimal weights
ret_matrix_outofsample <- Ret_outofSample$`2022-12-31`[,colnames(returns)]
portfolio_returns <- ret_matrix_outofsample  %*%  weights
# Calculate cumulative returns
cumulative_returns <- cumprod(1 + portfolio_returns) - 1
# Plot the cumulative returns
plot(cumulative_returns, type = "l", col = "green", lwd = 2,
main = "Portfolio Performance",
xlab = "Time Period", ylab = "Cumulative Returns")
naive <- NaiveDiversification(ret_matrix_outofsample)
# cleaning variables and graphs
rm(list=ls())
graphics.off()
# cleaning variables and graphs
rm(list=ls())
graphics.off()
library(foreach)
library(doParallel)
# Create a cluster with 4 cores
cl <- makeCluster(4)
registerDoParallel(cl)
# Define a list of matrices
lst <- list(matrix(1:9, ncol = 3), matrix(10:18, ncol = 3), matrix(19:27, ncol = 3))
# Parallelize the for loop
result <- foreach(mat = lst, .combine = max) %dopar% {
max(mat)
}
install.packages(foreach)
install.packages("foreach")
install.packages("foreach")
install.packages(doParallel)
install.packages("doParallel")
library(foreach)
library(doParallel)
# Create a cluster with 4 cores
cl <- makeCluster(4)
registerDoParallel(cl)
# Define a list of matrices
lst <- list(matrix(1:9, ncol = 3), matrix(10:18, ncol = 3), matrix(19:27, ncol = 3))
# Parallelize the for loop
result <- foreach(mat = lst, .combine = max) %dopar% {
max(mat)
}
# Stop the cluster
stopCluster(cl)
print(lst)
# Print the result
print(result)
# setting R project environment
my_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(my_dir)
# cleaning variables and graphs
rm(list=ls())
graphics.off()
# Load required packages
library(tidyverse)     # Data manipulation and visualization
library(tidyquant)     # Financial data analysis
library(readxl)        # Read excel files
library(rugarch)       # Univariate GARCH modeling
library(fGarch)        # Multivariate GARCH modeling
library(copula)        # Copula modeling
library(Rsolnp)        # Nonlinear optimization
library(fPortfolio)    # Portfolio optimization
library(PerformanceAnalytics) # Performance metrics
library(xts)           # Time series object
library(timetk)        # Time series object
library(xtable)        # Create LaTex tables
library(ggplot2)       # Produce graph
library("ROI")         # Optimization
library("ROI.plugin.glpk") # Optimization
library("ROI.plugin.quadprog") # Optimization
library("ROI.plugin.alabama") # Optimization
library(parallel)
library(foreach)
# Importing modules
source("garch_estimate.R")
source("copula_estimate.R")
source("portfolio_optimization.R")
source("pipeline_module.R")
# Fetch data
# OBSERVATION: CSIP6 was removed from data due to impossibility of found data
Ret <- read_excel("data_directory/StockPrice.xlsx")[-1,] %>%
mutate(date = as.Date(data), # convert to date format
across(VALE3:WHMT3, as.numeric)) %>%  # convert to numeric format
select(date, everything(), -data) %>% # select date and tickers
gather("Ticker", "AdjClose", -date, na.rm = TRUE) %>% # adjust to panel data
group_by(Ticker) %>% # calculate return for each ticker
mutate(Ret = log(AdjClose/ dplyr::lag(AdjClose))) %>%  # compute log return
ungroup() %>% # stop grouping tickers
select(date, Ticker, Ret) %>% # selecting necessary columns
spread(key = "Ticker", value = "Ret", fill = 0) # transforming data
Ret
# Choosing stocks on Ibovespa per year
MarketComposition <- read_excel("data_directory/MarketComposition.xlsx") %>%
mutate(date = as.Date(Data), # convert to date format
m = month(date, label = TRUE)) %>% # convert to numeric format
dplyr::filter(m == "dez") %>% # update factors
select(date, everything(),-c(Data, m)) %>% # select date, month and tickers
gather("Ticker", "Composition", -date, na.rm=TRUE) %>% # adjust to panel data
group_by(date) %>% # Select tickers by last date of the month
reframe(Tickers = Ticker)
MarketComposition
Update <- MarketComposition %>%
select(date) %>%
unique() %>% # avoid repetition
deframe() # create vector
Update
Symbols <- map(Update, .f = function(x){ # list of vectors with Ibov tickers per year
MarketComposition %>%
dplyr::filter(date == x) %>% # choose stocks presented on Ibov
select(Tickers) %>%
unique() %>% # avoid repetition
deframe() # create vector
})
names(Symbols) <- Update
Symbols
# Filtering stocks on Ibovespa and splitting  data set
Ret_inSample <- map(Update, .f = function(x){
Ret %>%
select(date,  Symbols[[paste(x)]]) %>% # filter Ibov stocks
dplyr::filter(date > as.Date(x) - 365, # split data in in-sample
date <= as.Date(x)) %>%
select(-date) %>% # exclude date column
as.matrix() # convert to matrix format
})
names(Ret_inSample) <- Update
Ret_inSample
Ret_outofSample <- map(Update, .f = function(x){
Ret %>%
select(date,  Symbols[[paste(x)]]) %>% # filter Ibov stocks
dplyr::filter(date > as.Date(x), # split data in out-of-sample
date <= as.Date(x) + 365) %>%
select(-date) %>% # exclude date column
as.matrix() # convert to matrix format
})
names(Ret_outofSample) <- Update + 365
Ret_outofSample
results <- PipelineParallel(Ret_inSample, Ret_outofSample, Update, copulas = c("Frank", "Gumbel"),
Alpha = 0.05, TargetReturn = 0, NumAssets = 8)
# Importing modules
source("garch_estimate.R")
results <- PipelineParallel(Ret_inSample, Ret_outofSample, Update, copulas = c("Frank", "Gumbel"),
Alpha = 0.05, TargetReturn = 0, NumAssets = 8)
PipelineParallel <- function(inSample, outofSample, Update, copulas,
Alpha = 0.05, TargetReturn = 0, NumAssets = 8){
# Set seed
set.seed(2023)
# Setting up parallel backend
registerDoParallel(cores = detectCores())
# Create a foreach loop with parallel execution
ParallelComputing <- foreach(x = Update, .combine = "bind_rows") %dopar% {
source("garch_estimate.R")
source("copula_estimate.R")
source("portfolio_optimization.R")
# Create returns matrix
returns <- inSample[[paste(x)]]
# Fit the GARCH model to the returns data
fit_garch <- FitGarch(returns)
# Subset the matrix to keep only columns with complete cases
garch_coef <- Filter(Negate(is.null), fit_garch$garch_coef)
unif_dist <- fit_garch$unif_dist
unif_dist <- unif_dist[, complete.cases(t(unif_dist))]
sigma <- fit_garch$sigma
returns <- returns[, complete.cases(t(sigma))]
sigma <- sigma[,complete.cases(t(sigma))]
# Generating Mixture-Copula
copula_mixture <- tryCatch(
{
OptMixtureCopulas(unif_dist, K = 10000, combination = copulas)
},
error = function(e) {
unif_dist <- ifelse(unif_dist < 0.01, 0.01, unif_dist)
unif_dist <- ifelse(unif_dist > 0.99, 0.99, unif_dist)
OptMixtureCopulas(unif_dist, K = 10000, combination = copulas)
}
)
# Compute simulated standardized residuals using the mixture-copula and GARCH
zsim <- ComputeZSim(copula_mixture = copula_mixture,
garch_coef = garch_coef)
# Predict future returns using the GARCH model, simulated residuals, and volatility estimates
ret_pred <- PredictGarch(returns = returns,
sigma = sigma,
zsim = zsim,
garch_coef = garch_coef)
ret_pred <- as.data.frame(ret_pred)
colnames(ret_pred) <- colnames(returns)
# Perform CVaR optimization to determine the optimal portfolio weights
weights <- rep(0, ncol(returns))
names(weights) <- colnames(returns)
weights <- CVaROptimization(returns = ret_pred,
Alpha = Alpha,
TargetReturn = TargetReturn,
NumAssets = NumAssets)
# Calculate portfolio returns based on the optimal weights
ret_matrix_outofsample <- outofSample[[paste(as.Date(x) + 365)]][,colnames(returns)]
portfolio_returns <- as.data.frame(ret_matrix_outofsample  %*%  weights)
# Retorna o resultado da iteração
return(data.frame(portfolio_returns))
}
# Stop parallel backend
stopImplicitCluster()
return(ParallelComputing)
}
results <- PipelineParallel(Ret_inSample, Ret_outofSample, Update, copulas = c("Frank", "Gumbel"),
Alpha = 0.05, TargetReturn = 0, NumAssets = 8)
PipelineParallel <- function(inSample, outofSample, Update, copulas,
Alpha = 0.05, TargetReturn = 0, NumAssets = 8){
# Set seed
set.seed(2023)
# Setting up parallel backend
registerDoParallel(cores = detectCores())
# Create a foreach loop with parallel execution
ParallelComputing <- foreach(x = Update, .combine = "bind_rows") %dopar% {
# Create returns matrix
returns <- inSample[[paste(x)]]
# Fit the GARCH model to the returns data
fit_garch <- FitGarch(returns)
# Subset the matrix to keep only columns with complete cases
garch_coef <- Filter(Negate(is.null), fit_garch$garch_coef)
unif_dist <- fit_garch$unif_dist
unif_dist <- unif_dist[, complete.cases(t(unif_dist))]
sigma <- fit_garch$sigma
returns <- returns[, complete.cases(t(sigma))]
sigma <- sigma[,complete.cases(t(sigma))]
# Generating Mixture-Copula
copula_mixture <- tryCatch(
{
OptMixtureCopulas(unif_dist, K = 10000, combination = copulas)
},
error = function(e) {
unif_dist <- ifelse(unif_dist < 0.01, 0.01, unif_dist)
unif_dist <- ifelse(unif_dist > 0.99, 0.99, unif_dist)
OptMixtureCopulas(unif_dist, K = 10000, combination = copulas)
}
)
# Compute simulated standardized residuals using the mixture-copula and GARCH
zsim <- ComputeZSim(copula_mixture = copula_mixture,
garch_coef = garch_coef)
# Predict future returns using the GARCH model, simulated residuals, and volatility estimates
ret_pred <- PredictGarch(returns = returns,
sigma = sigma,
zsim = zsim,
garch_coef = garch_coef)
ret_pred <- as.data.frame(ret_pred)
colnames(ret_pred) <- colnames(returns)
# Perform CVaR optimization to determine the optimal portfolio weights
weights <- rep(0, ncol(returns))
names(weights) <- colnames(returns)
weights <- CVaROptimization(returns = ret_pred,
Alpha = Alpha,
TargetReturn = TargetReturn,
NumAssets = NumAssets)
# Calculate portfolio returns based on the optimal weights
ret_matrix_outofsample <- outofSample[[paste(as.Date(x) + 365)]][,colnames(returns)]
portfolio_returns <- as.data.frame(ret_matrix_outofsample  %*%  weights)
# Retorna o resultado da iteração
return(data.frame(portfolio_returns))
}
# Stop parallel backend
stopImplicitCluster()
return(ParallelComputing)
}
results <- PipelineParallel(Ret_inSample, Ret_outofSample, Update, copulas = c("Frank", "Gumbel"),
Alpha = 0.05, TargetReturn = 0, NumAssets = 8)
PipelineParallel <- function(inSample, outofSample, Update, copulas,
Alpha = 0.05, TargetReturn = 0, NumAssets = 8){
# Set seed
set.seed(2023)
# Setting up parallel backend
registerDoParallel(cores = detectCores())
# Create a foreach loop with parallel execution
ParallelComputing <- foreach(x = Update, .combine = "bind_rows") %dopar% {
source("garch_estimate.R")
source("copula_estimate.R")
source("portfolio_optimization.R")
# Create returns matrix
returns <- inSample[[paste(x)]]
# Fit the GARCH model to the returns data
fit_garch <- FitGarch(returns)
# Subset the matrix to keep only columns with complete cases
garch_coef <- Filter(Negate(is.null), fit_garch$garch_coef)
unif_dist <- fit_garch$unif_dist
unif_dist <- unif_dist[, complete.cases(t(unif_dist))]
sigma <- fit_garch$sigma
returns <- returns[, complete.cases(t(sigma))]
sigma <- sigma[,complete.cases(t(sigma))]
# Generating Mixture-Copula
copula_mixture <- tryCatch(
{
OptMixtureCopulas(unif_dist, K = 10000, combination = copulas)
},
error = function(e) {
unif_dist <- ifelse(unif_dist < 0.01, 0.01, unif_dist)
unif_dist <- ifelse(unif_dist > 0.99, 0.99, unif_dist)
OptMixtureCopulas(unif_dist, K = 10000, combination = copulas)
}
)
# Compute simulated standardized residuals using the mixture-copula and GARCH
zsim <- ComputeZSim(copula_mixture = copula_mixture,
garch_coef = garch_coef)
# Predict future returns using the GARCH model, simulated residuals, and volatility estimates
ret_pred <- PredictGarch(returns = returns,
sigma = sigma,
zsim = zsim,
garch_coef = garch_coef)
ret_pred <- as.data.frame(ret_pred)
colnames(ret_pred) <- colnames(returns)
# Perform CVaR optimization to determine the optimal portfolio weights
weights <- rep(0, ncol(returns))
names(weights) <- colnames(returns)
weights <- CVaROptimization(returns = ret_pred,
Alpha = Alpha,
TargetReturn = TargetReturn,
NumAssets = NumAssets)
# Calculate portfolio returns based on the optimal weights
ret_matrix_outofsample <- outofSample[[paste(as.Date(x) + 365)]][,colnames(returns)]
portfolio_returns <- as.data.frame(ret_matrix_outofsample  %*%  weights)
# Retorna o resultado da iteração
return(data.frame(portfolio_returns))
}
# Stop parallel backend
stopImplicitCluster()
return(ParallelComputing)
}
ample, Ret_outofSample, Update, copulas = c("Frank", "Gumbel"),
results <- PipelineParallel(Ret_inSample, Ret_outofSample, Update, copulas = c("Frank", "Gumbel"),
Alpha = 0.05, TargetReturn = 0, NumAssets = 8)
# setting R project environment
my_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(my_dir)
# cleaning variables and graphs
rm(list=ls())
graphics.off()
# Load required packages
library(tidyverse)     # Data manipulation and visualization
library(tidyquant)     # Financial data analysis
library(readxl)        # Read excel files
library(rugarch)       # Univariate GARCH modeling
library(fGarch)        # Multivariate GARCH modeling
library(copula)        # Copula modeling
library(Rsolnp)        # Nonlinear optimization
library(fPortfolio)    # Portfolio optimization
library(PerformanceAnalytics) # Performance metrics
library(xts)           # Time series object
library(timetk)        # Time series object
library(xtable)        # Create LaTex tables
library(ggplot2)       # Produce graph
library("ROI")         # Optimization
library("ROI.plugin.glpk") # Optimization
library("ROI.plugin.quadprog") # Optimization
library("ROI.plugin.alabama") # Optimization
# Importing modules
source("garch_estimate.R")
source("copula_estimate.R")
source("portfolio_optimization.R")
source("pipeline_module.R")
# Fetch data
# OBSERVATION: CSIP6 was removed from data due to impossibility of found data
Ret <- read_excel("data_directory/StockPrice.xlsx")[-1,] %>%
mutate(date = as.Date(data), # convert to date format
across(VALE3:WHMT3, as.numeric)) %>%  # convert to numeric format
select(date, everything(), -data) %>% # select date and tickers
gather("Ticker", "AdjClose", -date, na.rm = TRUE) %>% # adjust to panel data
group_by(Ticker) %>% # calculate return for each ticker
mutate(Ret = log(AdjClose/ dplyr::lag(AdjClose))) %>%  # compute log return
ungroup() %>% # stop grouping tickers
select(date, Ticker, Ret) %>% # selecting necessary columns
spread(key = "Ticker", value = "Ret", fill = 0) # transforming data
# Fetch data
# OBSERVATION: CSIP6 was removed from data due to impossibility of found data
Ret <- read_excel("data_directory/StockPrice.xlsx")[-1,] %>%
mutate(date = as.Date(data), # convert to date format
across(VALE3:WHMT3, as.numeric)) %>%  # convert to numeric format
select(date, everything(), -data) %>% # select date and tickers
gather("Ticker", "AdjClose", -date, na.rm = TRUE) %>% # adjust to panel data
group_by(Ticker) %>% # calculate return for each ticker
mutate(Ret = log(AdjClose/ dplyr::lag(AdjClose))) %>%  # compute log return
ungroup() %>% # stop grouping tickers
select(date, Ticker, Ret) %>% # selecting necessary columns
spread(key = "Ticker", value = "Ret", fill = 0) # transforming data
Ret
# Choosing stocks on Ibovespa per year
MarketComposition <- read_excel("data_directory/MarketComposition.xlsx") %>%
mutate(date = as.Date(Data), # convert to date format
m = month(date, label = TRUE)) %>% # convert to numeric format
dplyr::filter(m == "dez") %>% # update factors
select(date, everything(),-c(Data, m)) %>% # select date, month and tickers
gather("Ticker", "Composition", -date, na.rm=TRUE) %>% # adjust to panel data
group_by(date) %>% # Select tickers by last date of the month
reframe(Tickers = Ticker)
MarketComposition
Update <- MarketComposition %>%
select(date) %>%
unique() %>% # avoid repetition
deframe() # create vector
Update
Symbols <- map(Update, .f = function(x){ # list of vectors with Ibov tickers per year
MarketComposition %>%
dplyr::filter(date == x) %>% # choose stocks presented on Ibov
select(Tickers) %>%
unique() %>% # avoid repetition
deframe() # create vector
})
names(Symbols) <- Update
Symbols
# Filtering stocks on Ibovespa and splitting  data set
Ret_inSample <- map(Update, .f = function(x){
Ret %>%
select(date,  Symbols[[paste(x)]]) %>% # filter Ibov stocks
dplyr::filter(date > as.Date(x) - 365, # split data in in-sample
date <= as.Date(x)) %>%
select(-date) %>% # exclude date column
as.matrix() # convert to matrix format
})
names(Ret_inSample) <- Update
Ret_inSample
Ret_outofSample <- map(Update, .f = function(x){
Ret %>%
select(date,  Symbols[[paste(x)]]) %>% # filter Ibov stocks
dplyr::filter(date > as.Date(x), # split data in out-of-sample
date <= as.Date(x) + 365) %>%
select(-date) %>% # exclude date column
as.matrix() # convert to matrix format
})
names(Ret_outofSample) <- Update + 365
Ret_outofSample
# Calculate cumulative returns
results <- Pipeline(Ret_inSample, Ret_outofSample, Update,
copulas = c("Gumbel", "t"), K = 100,
Alpha = 0.05, TargetReturn = 0, NumAssets = 8)
cumulative_returns <- cumprod(1 + results) - 1
# Plot the cumulative returns
plot(cumulative_returns, type = "l", col = "green", lwd = 1,
main = "Portfolio Performance",
xlab = "Time Period", ylab = "Cumulative Returns")
cumulative_returns
results
sum(results)
cumprod(1 + results) - 1
results + 1
cumprod(1 + results) - 1
cumulative_returns <- cumsum(results)
# Plot the cumulative returns
plot(cumulative_returns, type = "l", col = "green", lwd = 1,
main = "Portfolio Performance",
xlab = "Time Period", ylab = "Cumulative Returns")
cumulative_returns
# Plot the cumulative returns
plot(cumulative_returns$V1, type = "l", col = "green", lwd = 1,
main = "Portfolio Performance",
xlab = "Time Period", ylab = "Cumulative Returns")
