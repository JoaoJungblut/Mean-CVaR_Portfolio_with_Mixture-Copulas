dplyr::filter(date > as.Date(x), # split data in out-of-sample
date <= as.Date(x) + 365) %>%
select(-date) %>% # exclude date column
as.matrix() # convert to matrix format
})
names(Ret_outofSample) <- Update + 365
Ret_outofSample
# Calculate cumulative returns
results <- Pipeline(Ret_inSample, Ret_outofSample, Update,
copulas = c("Gumbel", "t"), K = 1000,
Alpha = 0.95, TargetReturn = 0, NumAssets = 8)
# Define a function to perform computations for each  window
Pipeline <- function(inSample, outofSample, Update, copulas, K = 10000,
Alpha = 0.95, TargetReturn = 0, NumAssets = 8){
# Set seed
set.seed(2023)
# Declaring arguments
K = K
Alpha = Alpha
TargetReturn = TargetReturn
NumAssets = NumAssets
# Setting my pipeline
Pipe <- map(Update, .f = function(x){
# Create returns matrix
returns <- inSample[[paste(x)]]
# Fit the GARCH model to the returns data
fit_garch <- FitGarch(returns)
# Subset the matrix to keep only columns with complete cases
garch_coef <- Filter(Negate(is.null), fit_garch$garch_coef) # Filtering NULL values
unif_dist <- fit_garch$unif_dist
unif_dist <- unif_dist[, complete.cases(t(unif_dist))] # drop Na columns
sigma <- fit_garch$sigma
returns <- returns[, complete.cases(t(sigma))] # drop invalid stocks
sigma <- sigma[,complete.cases(t(sigma))] # drop Na columns
# Generating Mixture-Copula
copula_mixture <- tryCatch(
{
OptMixtureCopulas(unif_dist, K = 10000, combination = copulas)
},
error = function(e) {
# If an error occurs, adjust uniform dist to have finite limits
unif_dist <- ifelse(unif_dist < 0.01, 0.01, unif_dist) # avoid convergence issues
unif_dist <- ifelse(unif_dist > 0.99, 0.99, unif_dist) # avoid convergence issues
# Retry
OptMixtureCopulas(unif_dist, K = K, combination = copulas)
}
)
# Compute simulated standardized residuals using the mixture-copula and GARCH
zsim <- ComputeZSim(copula_mixture = copula_mixture,
garch_coef = garch_coef)
# Predict future returns using the GARCH model, simulated residuals, and volatility estimates
ret_pred <- PredictGarch(returns = returns,
sigma = sigma,
zsim = zsim,
garch_coef = garch_coef)
ret_pred <- as.data.frame(ret_pred)
colnames(ret_pred) <- colnames(returns)
# Perform CVaR optimization to determine the optimal portfolio weights
weights <- CVaROptimization(returns = ret_pred,
Alpha = Alpha,
TargetReturn = TargetReturn,
NumAssets = NumAssets)
names(weights) <- colnames(returns)
# Calculate portfolio returns based on the optimal weights
ret_matrix_outofsample <- outofSample[[paste(as.Date(x) + 365)]][,colnames(returns)] # select valid stocks
portfolio_returns <- as.data.frame(ret_matrix_outofsample  %*%  weights)
}) %>%
bind_rows()
return(Pipe)
}
# Calculate cumulative returns
results <- Pipeline(Ret_inSample, Ret_outofSample, Update,
copulas = c("Gumbel", "t"), K = 1000,
Alpha = 0.95, TargetReturn = 0, NumAssets = 8)
# Define a function to perform computations for each  window
Pipeline <- function(inSample, outofSample, Update, copulas, K = 10000,
Alpha = 0.95, TargetReturn = 0, NumAssets = 8){
# Set seed
set.seed(2023)
# Setting my pipeline
Pipe <- map(Update, .f = function(x){
# Create returns matrix
returns <- inSample[[paste(x)]]
# Fit the GARCH model to the returns data
fit_garch <- FitGarch(returns)
# Subset the matrix to keep only columns with complete cases
garch_coef <- Filter(Negate(is.null), fit_garch$garch_coef) # Filtering NULL values
unif_dist <- fit_garch$unif_dist
unif_dist <- unif_dist[, complete.cases(t(unif_dist))] # drop Na columns
sigma <- fit_garch$sigma
returns <- returns[, complete.cases(t(sigma))] # drop invalid stocks
sigma <- sigma[,complete.cases(t(sigma))] # drop Na columns
# Generating Mixture-Copula
copula_mixture <- tryCatch(
{
OptMixtureCopulas(unif_dist, K = 10000, combination = copulas)
},
error = function(e) {
# If an error occurs, adjust uniform dist to have finite limits
unif_dist <- ifelse(unif_dist < 0.01, 0.01, unif_dist) # avoid convergence issues
unif_dist <- ifelse(unif_dist > 0.99, 0.99, unif_dist) # avoid convergence issues
# Retry
OptMixtureCopulas(unif_dist, K = K, combination = copulas)
}
)
# Compute simulated standardized residuals using the mixture-copula and GARCH
zsim <- ComputeZSim(copula_mixture = copula_mixture,
garch_coef = garch_coef)
# Predict future returns using the GARCH model, simulated residuals, and volatility estimates
ret_pred <- PredictGarch(returns = returns,
sigma = sigma,
zsim = zsim,
garch_coef = garch_coef)
ret_pred <- as.data.frame(ret_pred)
colnames(ret_pred) <- colnames(returns)
# Perform CVaR optimization to determine the optimal portfolio weights
weights <- CVaROptimization(returns = ret_pred,
Alpha = Alpha,
TargetReturn = TargetReturn,
NumAssets = NumAssets)
names(weights) <- colnames(returns)
# Calculate portfolio returns based on the optimal weights
ret_matrix_outofsample <- outofSample[[paste(as.Date(x) + 365)]][,colnames(returns)] # select valid stocks
portfolio_returns <- as.data.frame(ret_matrix_outofsample  %*%  weights)
}) %>%
bind_rows()
return(Pipe)
}
# setting R project environment
my_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(my_dir)
# cleaning variables and graphs
rm(list=ls())
graphics.off()
# Load required packages
library(tidyverse)     # Data manipulation and visualization
library(tidyquant)     # Financial data analysis
library(readxl)        # Read excel files
library(rugarch)       # Univariate GARCH modeling
library(fGarch)        # Multivariate GARCH modeling
library(copula)        # Copula modeling
library(Rsolnp)        # Nonlinear optimization
library(fPortfolio)    # Portfolio optimization
library(PerformanceAnalytics) # Performance metrics
library(xts)           # Time series object
library(timetk)        # Time series object
library(xtable)        # Create LaTex tables
library(ggplot2)       # Produce graph
library("ROI")         # Optimization
library("ROI.plugin.glpk") # Optimization
library("ROI.plugin.quadprog") # Optimization
library("ROI.plugin.alabama") # Optimization
library("ROML") # Portfolio Optimization
library("ROML.portfolio") # Portfolio Optimization
# Importing modules
source("pipeline_module.R")
# Fetch data
# OBSERVATION: CSIP6 was removed from data due to impossibility of found data
Ret <- read_excel("data_directory/StockPrice.xlsx")[-1,] %>%
mutate(date = as.Date(data), # convert to date format
across(VALE3:WHMT3, as.numeric)) %>%  # convert to numeric format
select(date, everything(), -data) %>% # select date and tickers
gather("Ticker", "AdjClose", -date, na.rm = TRUE) %>% # adjust to panel data
group_by(Ticker) %>% # calculate return for each ticker
mutate(Ret = log(AdjClose/ dplyr::lag(AdjClose))) %>%  # compute log return
ungroup() %>% # stop grouping tickers
select(date, Ticker, Ret) %>% # selecting necessary columns
spread(key = "Ticker", value = "Ret", fill = 0) # transforming data
Ret
# Choosing stocks on Ibovespa per year
MarketComposition <- read_excel("data_directory/MarketComposition.xlsx") %>%
mutate(date = as.Date(Data), # convert to date format
m = month(date, label = TRUE)) %>% # convert to numeric format
dplyr::filter(m == "dez") %>% # update factors
select(date, everything(),-c(Data, m)) %>% # select date, month and tickers
gather("Ticker", "Composition", -date, na.rm=TRUE) %>% # adjust to panel data
group_by(date) %>% # Select tickers by last date of the month
reframe(Tickers = Ticker)
MarketComposition
Update <- MarketComposition %>%
select(date) %>%
unique() %>% # avoid repetition
deframe() # create vector
Update
Symbols <- map(Update, .f = function(x){ # list of vectors with Ibov tickers per year
MarketComposition %>%
dplyr::filter(date == x) %>% # choose stocks presented on Ibov
select(Tickers) %>%
unique() %>% # avoid repetition
deframe() # create vector
})
names(Symbols) <- Update
Symbols
# Filtering stocks on Ibovespa and splitting  data set
Ret_inSample <- map(Update, .f = function(x){
Ret %>%
select(date,  Symbols[[paste(x)]]) %>% # filter Ibov stocks
dplyr::filter(date > as.Date(x) - 365, # split data in in-sample
date <= as.Date(x)) %>%
select(-date) %>% # exclude date column
as.matrix() # convert to matrix format
})
names(Ret_inSample) <- Update
Ret_inSample
Ret_outofSample <- map(Update, .f = function(x){
Ret %>%
select(date,  Symbols[[paste(x)]]) %>% # filter Ibov stocks
dplyr::filter(date > as.Date(x), # split data in out-of-sample
date <= as.Date(x) + 365) %>%
select(-date) %>% # exclude date column
as.matrix() # convert to matrix format
})
names(Ret_outofSample) <- Update + 365
Ret_outofSample
# Calculate cumulative returns
results <- Pipeline(Ret_inSample, Ret_outofSample, Update,
copulas = c("Gumbel", "t"), K = 1000,
Alpha = 0.95, TargetReturn = 0, NumAssets = 8)
# setting R project environment
my_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(my_dir)
# cleaning variables and graphs
rm(list=ls())
graphics.off()
# Load required packages
library(tidyverse)     # Data manipulation and visualization
library(tidyquant)     # Financial data analysis
library(readxl)        # Read excel files
library(rugarch)       # Univariate GARCH modeling
library(fGarch)        # Multivariate GARCH modeling
library(copula)        # Copula modeling
library(Rsolnp)        # Nonlinear optimization
library(fPortfolio)    # Portfolio optimization
library(PerformanceAnalytics) # Performance metrics
library(xts)           # Time series object
library(timetk)        # Time series object
library(xtable)        # Create LaTex tables
library(ggplot2)       # Produce graph
library("ROI")         # Optimization
library("ROI.plugin.glpk") # Optimization
library("ROI.plugin.quadprog") # Optimization
library("ROI.plugin.alabama") # Optimization
library("ROML") # Portfolio Optimization
library("ROML.portfolio") # Portfolio Optimization
# Importing modules
source("garch_estimate.R")
source("copula_estimate.R")
source("portfolio_optimization.R")
source("pipeline_module.R")
# Fetch data
# OBSERVATION: CSIP6 was removed from data due to impossibility of found data
Ret <- read_excel("data_directory/StockPrice.xlsx")[-1,] %>%
mutate(date = as.Date(data), # convert to date format
across(VALE3:WHMT3, as.numeric)) %>%  # convert to numeric format
select(date, everything(), -data) %>% # select date and tickers
gather("Ticker", "AdjClose", -date, na.rm = TRUE) %>% # adjust to panel data
group_by(Ticker) %>% # calculate return for each ticker
mutate(Ret = log(AdjClose/ dplyr::lag(AdjClose))) %>%  # compute log return
ungroup() %>% # stop grouping tickers
select(date, Ticker, Ret) %>% # selecting necessary columns
spread(key = "Ticker", value = "Ret", fill = 0) # transforming data
Ret
# Choosing stocks on Ibovespa per year
MarketComposition <- read_excel("data_directory/MarketComposition.xlsx") %>%
mutate(date = as.Date(Data), # convert to date format
m = month(date, label = TRUE)) %>% # convert to numeric format
dplyr::filter(m == "dez") %>% # update factors
select(date, everything(),-c(Data, m)) %>% # select date, month and tickers
gather("Ticker", "Composition", -date, na.rm=TRUE) %>% # adjust to panel data
group_by(date) %>% # Select tickers by last date of the month
reframe(Tickers = Ticker)
MarketComposition
Update <- MarketComposition %>%
select(date) %>%
unique() %>% # avoid repetition
deframe() # create vector
Update
Symbols <- map(Update, .f = function(x){ # list of vectors with Ibov tickers per year
MarketComposition %>%
dplyr::filter(date == x) %>% # choose stocks presented on Ibov
select(Tickers) %>%
unique() %>% # avoid repetition
deframe() # create vector
})
names(Symbols) <- Update
Symbols
# Filtering stocks on Ibovespa and splitting  data set
Ret_inSample <- map(Update, .f = function(x){
Ret %>%
select(date,  Symbols[[paste(x)]]) %>% # filter Ibov stocks
dplyr::filter(date > as.Date(x) - 365, # split data in in-sample
date <= as.Date(x)) %>%
select(-date) %>% # exclude date column
as.matrix() # convert to matrix format
})
names(Ret_inSample) <- Update
Ret_inSample
Ret_outofSample <- map(Update, .f = function(x){
Ret %>%
select(date,  Symbols[[paste(x)]]) %>% # filter Ibov stocks
dplyr::filter(date > as.Date(x), # split data in out-of-sample
date <= as.Date(x) + 365) %>%
select(-date) %>% # exclude date column
as.matrix() # convert to matrix format
})
names(Ret_outofSample) <- Update + 365
Ret_outofSample
# Declaring arguments
K = 1000
Alpha = 0.95
TargetReturn = TargetReturn
# Declaring arguments
K = 1000
Alpha = 0.95
TargetReturn = 0
NumAssets = 8
# Calculate cumulative returns
results <- Pipeline(Ret_inSample, Ret_outofSample, Update,
copulas = c("Gumbel", "t"), K = 1000,
Alpha = 0.95, TargetReturn = 0, NumAssets = 8)
cumulative_returns <- cumsum(results)
# Plot the cumulative returns
plot(cumulative_returns$V1, type = "l", col = "black", lwd = 1,
main = "Portfolio Performance",
xlab = "Time Period", ylab = "Cumulative Returns")
install.packages("osmdata")
library(osmdata)
# São Paulo, Brasil
cidade_sp <- opq("São Paulo, Brazil")
tags <- c("shop", "signage")
sp_data <- osmdata_sf(cidade_sp, tags = tags)
library(sf)
library(tmap)
# Instale e carregue os pacotes necessários
install.packages(c("osmdata", "sf", "tmap"))
# Instale e carregue os pacotes necessários
install.packages(c("osmdata", "sf", "tmap"))
install.packages(c("osmdata", "sf", "tmap"))
library(osmdata)
library(sf)
library(tmap)
# Defina uma área geográfica de interesse
cidade_sp <- opq("São Paulo, Brazil")
# Baixe os dados do OpenStreetMap
sp_data <- osmdata_download(cidade_sp)
# Defina uma área geográfica de interesse
cidade_sp <- opq("São Paulo, Brazil")
# Baixe e converta os dados do OpenStreetMap para um objeto sf
sp_data_sf <- osmdata_sf(cidade_sp)
# Visualize os dados
tm_shape(sp_data_sf$osm_points) +
tm_bubbles(size = 0.2, col = "red", alpha = 0.7) +
tm_layout(legend.position = c("left", "bottom"))
# setting R project environment
my_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(my_dir)
# cleaning variables and graphs
rm(list=ls())
graphics.off()
# Load required packages
library(tidyverse)     # Data manipulation and visualization
library(tidyquant)     # Financial data analysis
library(readxl)        # Read excel files
library(rugarch)       # Univariate GARCH modeling
library(fGarch)        # Multivariate GARCH modeling
library(copula)        # Copula modeling
library(Rsolnp)        # Nonlinear optimization
library(fPortfolio)    # Portfolio optimization
library(PerformanceAnalytics) # Performance metrics
library(xts)           # Time series object
library(timetk)        # Time series object
library(xtable)        # Create LaTex tables
library(ggplot2)       # Produce graph
library("ROI")         # Optimization
library("ROI.plugin.glpk") # Optimization
library("ROI.plugin.quadprog") # Optimization
library("ROI.plugin.alabama") # Optimization
library("ROML") # Portfolio Optimization
library("ROML.portfolio") # Portfolio Optimization
# Importing modules
source("garch_estimate.R")
source("copula_estimate.R")
source("portfolio_optimization.R")
source("pipeline_module.R")
# Fetch data
# OBSERVATION: CSIP6 was removed from data due to impossibility of found data
Ret <- read_excel("data_directory/StockPrice.xlsx")[-1,] %>%
mutate(date = as.Date(data), # convert to date format
across(VALE3:WHMT3, as.numeric)) %>%  # convert to numeric format
select(date, everything(), -data) %>% # select date and tickers
gather("Ticker", "AdjClose", -date, na.rm = TRUE) %>% # adjust to panel data
group_by(Ticker) %>% # calculate return for each ticker
mutate(Ret = log(AdjClose/ dplyr::lag(AdjClose))) %>%  # compute log return
ungroup() %>% # stop grouping tickers
select(date, Ticker, Ret) %>% # selecting necessary columns
spread(key = "Ticker", value = "Ret", fill = 0) # transforming data
Ret
# Choosing stocks on Ibovespa per year
MarketComposition <- read_excel("data_directory/MarketComposition.xlsx") %>%
mutate(date = as.Date(Data), # convert to date format
m = month(date, label = TRUE)) %>% # convert to numeric format
dplyr::filter(m == "dez") %>% # update factors
select(date, everything(),-c(Data, m)) %>% # select date, month and tickers
gather("Ticker", "Composition", -date, na.rm=TRUE) %>% # adjust to panel data
group_by(date) %>% # Select tickers by last date of the month
reframe(Tickers = Ticker)
MarketComposition
Update <- MarketComposition %>%
select(date) %>%
unique() %>% # avoid repetition
deframe() # create vector
Update
Symbols <- map(Update, .f = function(x){ # list of vectors with Ibov tickers per year
MarketComposition %>%
dplyr::filter(date == x) %>% # choose stocks presented on Ibov
select(Tickers) %>%
unique() %>% # avoid repetition
deframe() # create vector
})
names(Symbols) <- Update
Symbols
# Filtering stocks on Ibovespa and splitting  data set
Ret_inSample <- map(Update, .f = function(x){
Ret %>%
select(date,  Symbols[[paste(x)]]) %>% # filter Ibov stocks
dplyr::filter(date > as.Date(x) - 365, # split data in in-sample
date <= as.Date(x)) %>%
select(-date) %>% # exclude date column
as.matrix() # convert to matrix format
})
names(Ret_inSample) <- Update
Ret_inSample
Ret_outofSample <- map(Update, .f = function(x){
Ret %>%
select(date,  Symbols[[paste(x)]]) %>% # filter Ibov stocks
dplyr::filter(date > as.Date(x), # split data in out-of-sample
date <= as.Date(x) + 365) %>%
select(-date) %>% # exclude date column
as.matrix() # convert to matrix format
})
names(Ret_outofSample) <- Update + 365
Ret_outofSample
# Declaring arguments in global environment
K = 100
Alpha = 0.95
TargetReturn = 0
NumAssets = 12
copulas = c("Clayton", "Gumbel", "t")
pi = c(Clayton = 1/3, Gumbel = 1/3, t = 1/3)
# Calculate cumulative returns
results <- Pipeline(Ret_inSample, Ret_outofSample, Update,
copulas = copulas, K = K, pi = pi,
Alpha = Alpha, TargetReturn = TargetReturn, NumAssets = NumAssets)
cumulative_returns <- cumsum(results)
# Plot the cumulative returns
plot(cumulative_returns$V1, type = "l", col = "black", lwd = 1,
main = "Portfolio Performance",
xlab = "Time Period", ylab = "Cumulative Returns")
# setting R project environment
my_dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(my_dir)
# cleaning variables and graphs
rm(list=ls())
graphics.off()
# Load required packages
library(tidyverse)     # Data manipulation and visualization
library(tidyquant)     # Financial data analysis
library(readxl)        # Read excel files
library(rugarch)       # Univariate GARCH modeling
library(fGarch)        # Multivariate GARCH modeling
library(copula)        # Copula modeling
library(Rsolnp)        # Nonlinear optimization
library(fPortfolio)    # Portfolio optimization
library(PerformanceAnalytics) # Performance metrics
library(xts)           # Time series object
library(timetk)        # Time series object
library(xtable)        # Create LaTex tables
library(ggplot2)       # Produce graph
library("ROI")         # Optimization
library("ROI.plugin.glpk") # Optimization
library("ROI.plugin.quadprog") # Optimization
library("ROI.plugin.alabama") # Optimization
library("ROML") # Portfolio Optimization
library("ROML.portfolio") # Portfolio Optimization
# Importing modules
source("garch_estimate.R")
source("copula_estimate.R")
source("portfolio_optimization.R")
source("pipeline_module.R")
# Fetch data
# OBSERVATION: CSIP6 was removed from data due to impossibility of found data
Ret <- read_excel("data_directory/StockPrice.xlsx")[-1,] %>%
mutate(date = as.Date(data), # convert to date format
across(VALE3:WHMT3, as.numeric)) %>%  # convert to numeric format
select(date, everything(), -data) %>% # select date and tickers
gather("Ticker", "AdjClose", -date, na.rm = TRUE) %>% # adjust to panel data
group_by(Ticker) %>% # calculate return for each ticker
mutate(Ret = log(AdjClose/ dplyr::lag(AdjClose))) %>%  # compute log return
ungroup() %>% # stop grouping tickers
select(date, Ticker, Ret) %>% # selecting necessary columns
spread(key = "Ticker", value = "Ret", fill = 0) # transforming data
Ret
# Choosing stocks on Ibovespa per year
MarketComposition <- read_excel("data_directory/MarketComposition.xlsx") %>%
mutate(date = as.Date(Data), # convert to date format
m = month(date, label = TRUE)) %>% # convert to numeric format
dplyr::filter(m == "dez") %>% # update factors
select(date, everything(),-c(Data, m)) %>% # select date, month and tickers
gather("Ticker", "Composition", -date, na.rm=TRUE) %>% # adjust to panel data
group_by(date) %>% # Select tickers by last date of the month
reframe(Tickers = Ticker)
MarketComposition
