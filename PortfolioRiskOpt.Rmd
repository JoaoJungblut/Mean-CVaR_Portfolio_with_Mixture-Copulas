---
title: "Worst-case CVaR portfolio optimization with cardinality constraints based copula approach"
author: "Jo√£o Ramos Jungblut"
date: "`r Sys.Date()`"
output: html_document
---

# Load required packages

- **tidyverse**: Data manipulation and visualization.
- **tidyquant**: Financial data analysis.
- **rugarch**: Univariate GARCH modeling.
- **fGarch**: Multivariate GARCH modeling.
- **copula**: Copula modeling.
- **Rsolnp**: Nonlinear optimization.
- **fPortfolio**: Portfolio optimization.

```{r, echo=TRUE, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE}
# Load required packages
library(tidyverse)     # Data manipulation and visualization
library(tidyquant)     # Financial data analysis
library(rugarch)       # Univariate GARCH modeling
library(fGarch)        # Multivariate GARCH modeling
library(copula)        # Copula modeling
library(Rsolnp)        # Nonlinear optimization
library(fPortfolio)    # Portfolio optimization

```

# Importing data and calculating returns

The code snippet imports financial data and calculates returns for a set of stocks using the following steps:

1. Use the `tidyquant::tq_get()` function to fetch historical price data for a list of stock symbols specified in the `c(...)` function. The data is retrieved from the specified start date ("1997-01-01") until the present.

2. Use the `dplyr` functions (`select()`, `group_by()`, `mutate()`, `ungroup()`, `spread()`, and `select()`) to manipulate the data:
   - Use `select()` to choose specific columns (date, symbol, adjusted) from the data.
   - Use `group_by()` to group the data by the stock symbols.
   - Use `mutate()` to calculate the log returns for each stock by taking the logarithmic difference of the adjusted prices.
   - Use `ungroup()` to remove the grouping.
   - Use `spread()` to restructure the data, spreading the stock symbols into separate columns with their corresponding returns.
   - Use `select()` to remove the "adjusted" column.

3. Use the `na.omit()` function to remove any rows with missing values (NA) in the data.

The resulting `returns` data frame contains the daily returns for each stock, with each stock represented as a separate column.


```{r, echo=TRUE, eval=TRUE, include=TRUE}
# Importing data and calculating returns
returns <- tidyquant::tq_get(c("PETR4.SA", "VALE3.SA", "ITUB4.SA",
                               "BBAS3.SA", "ABEV3.SA", "BBDC4.SA",
                               "GRND3.SA", "SMTO3.SA", "SLCE3.SA",
                               "VIVT3.SA", "B3SA3.SA", "UNIP6.SA",
                               "ELET6.SA", "MRFG3.SA", "BRKM5.SA"), 
                             from = "1997-01-01") %>% 
  dplyr::select(date, symbol, adjusted) %>% 
  dplyr::group_by(symbol) %>% 
  dplyr::mutate(return = log(adjusted) - log(dplyr::lag(adjusted))) %>% 
  dplyr::ungroup() %>% 
  dplyr::select(-adjusted) %>% 
  tidyr::spread(symbol, return) %>% 
  na.omit()

head(returns)
```


# Creating auxiliary matrices and list

- `N` is assigned the value of the number of columns in the `returns` matrix minus one, representing the number of assets in the portfolio.

- `K` is assigned the value of 252, which denotes the window size for GARCH estimation. This indicates that the code will perform calculations using a rolling window of 252 observations.

- `index_vector` is created using the `seq()` function. It generates a vector ranging from 1 to the number of rows in the `returns` matrix, with an increment of K. This vector serves as an index for rolling optimization.

- `names_vector` is assigned the names of the columns in the `returns` matrix, excluding the first column. It provides a reference for the asset names.

- `portfolio_daily_returns` is initialized as a matrix with the same number of rows as the `returns` matrix and one column. It is used to store the portfolio returns.

- The first K rows of `portfolio_daily_returns` are set to zero, initializing them as zero. This step is likely performed to indicate that the calculations for portfolio returns will start from the K+1 row forwards.


```{r, echo=TRUE, eval=TRUE, include=TRUE}
# Creating auxiliary matrices and list
N <- base::ncol(returns) - 1   # Number of assets
K <- 252                 # Window size for GARCH estimation
index_vector <- seq(1, nrow(returns), by = K)  # Index vector for rolling optimization
names_vector <- names(returns)[-1]   # Asset names for reference
portfolio_daily_returns <- matrix(nrow = nrow(returns), ncol = 1)  # Matrix to store portfolio returns
portfolio_daily_returns[1:K, ] <- 0  # Initialize the first K rows as zero
```



# Initialize the GARCH specification

The code snippet initializes the GARCH specification using the `rugarch::ugarchspec()` function.

- `mod_garch` is assigned the result of the function call. It attempts to create a GARCH specification but handles any errors silently using the `try()` function.

- The GARCH specification is defined with the following components:

  - `variance.model` specifies the variance model. In this case, it is set to a symmetric GARCH model (`model = "sGARCH"`) with an order of (1, 1) (`garchOrder = c(1, 1)`). The `variance.targeting` parameter is set to TRUE, indicating that the model should be estimated with variance targeting.

  - `mean.model` specifies the mean model. Here, it is set to an ARMA model with an order of (1, 0) (`armaOrder = c(1, 0)`), representing an autoregressive model of order 1.

  - `distribution.model` specifies the distribution of the standardized residuals. In this case, it is set to "sstd", which likely refers to a standardized distribution.

- If any errors occur during the execution of `rugarch::ugarchspec()`, they will be caught and handled silently due to the `silent = TRUE` parameter.

```{r, echo=TRUE, eval=TRUE, include=TRUE}
# Initialize the GARCH specification
mod_garch <- try(
  rugarch::ugarchspec(variance.model = list(model = "sGARCH",
                                            garchOrder = c(1, 1),
                                            variance.targeting = TRUE),
                      mean.model = list(armaOrder = c(1, 0)),
                      distribution.model = "sstd"),
  silent = TRUE
)
```



# Initialize copula objects

The code snippet initializes copula objects using functions from the `copula` package.

- `copt` is initialized as a t-Copula object using the `copula::tCopula()` function. It has a parameter value of 0.5 and a dimension of N, which represents the number of assets in the portfolio.

- `copC` is initialized as a Clayton copula object using the `copula::claytonCopula()` function. It has a delta parameter value of 2 and a dimension of N.

- `copG` is initialized as a Gumbel copula object using the `copula::gumbelCopula()` function. It has a theta parameter value of 2 and a dimension of N.

Next, the code defines lower and upper bounds for the copula parameters and weights:

- `lower` is a vector specifying the lower bounds for the copula parameters and weights. The values in the vector correspond to the Clayton copula parameter lower bound, Gumbel copula parameter lower bound, lower bounds for t parameters (correlation and degrees of freedom), and three weights.

- `upper` is a vector specifying the upper bounds for the copula parameters and weights. The values in the vector include the upper bound for the Clayton copula parameter, the upper bound for the Gumbel copula parameter, the upper bounds for t parameters, and three weights.

The code then initializes weights for the copulas, setting their initial guesses to 1/3 each:

- `par6` and `par5` are initialized as the weights for the Clayton and Gumbel copulas, respectively.

The code defines a negative log-likelihood function (`LLCG`) used for estimating copula weights and parameters:

- The function takes parameters, U (input data), copula objects (copC, copG, copt) as inputs.

- The Clayton, Gumbel, and t copula parameters and weights are set based on the input parameters.

- The function calculates the log-likelihood function, `opt`, by combining the density functions of the copulas with their corresponding weights.

- Infinite values in the log-likelihood are handled by replacing them with zeros.

- The function returns the negative sum of the log-likelihood.

Additionally, a constrain function (`eqfun`) is defined to ensure that the sum of the copula weights is equal to 1.

- The function takes parameters, U (input data), copula objects (copC, copG, copt) as inputs.

- The function calculates the sum of the copula weights and returns it.


```{r, echo=TRUE, eval=TRUE, include=TRUE}
# Initialize copula objects
copt <- copula::tCopula(param = 0.5, dim = N)  # t-Copula with parameter 0.5
copC <- copula::claytonCopula(2, dim = N)      # Clayton copula with delta = 2
copG <- copula::gumbelCopula(2, dim = N)       # Gumbel copula with theta = 2

# Define lower and upper bounds for the copula parameters and weights
lower <- c(0.1, 1, -0.9, (2 + .Machine$double.eps), 0, 0, 0)     
upper <- c(copC@param.upbnd, copG@param.upbnd, 1, 100, 1, 1, 1) 

# Initialize weights for copulas (initial guesses = 1/3 each)
par6 <- par5 <- par4 <- 1/3 

# Negative log-likelihood function for estimating copula weights and parameters
LLCG <- function(params, U, copC, copG, copt){ 
  # Set copula parameters
  slot(copC, "parameters") <- params[1]    # Initial Clayton parameter
  slot(copG, "parameters") <- params[2]    # Initial Gumbel parameter 
  slot(copt, "parameters") <- params[3:4]  # Initial t parameters (correlation and degrees of freedom)
  
  # Set copula weights
  pi1 <- params[5]  # Weight of Clayton copula
  pi2 <- params[6]  # Weight of Gumbel copula
  pi3 <- params[7]  # Weight of t copula
  
  # Calculate the log-likelihood function to be optimized
  opt <- log(pi1 * copula::dCopula(U, copC) + pi2 * copula::dCopula(U, copG) + pi3 * copula::dCopula(U, copt))
  
  # Handle infinite values in the log-likelihood
  if(any(is.infinite(opt))){
    opt[which(is.infinite(opt))] <- 0
  }
  
  # Return the negative sum of the log-likelihood
  -sum(opt)
}

# Constrain function to ensure sum(weights) = 1
eqfun <- function(params, U, copC, copG, copt){ 
  z <- params[5] + params[6] + params[7]
  return(z)
}
```

# Setting up a fPortfolio min CVaR optimization

The code snippet sets up a minimum Conditional Value at Risk (CVaR) optimization using the `fPortfolio` package.

- `cvar_opt` is initialized as a matrix with a number of rows equal to the length of the `index_vector` minus one and a number of columns equal to N (the number of assets in the portfolio). It will be used to store the results of the CVaR optimization.

- The `targetReturn` variable is set to 0, indicating a daily target return constraint. However, this line is duplicated, so the variable is set to 0 twice.

- `frontierSpec` is initialized as a portfolio specification object using the `fPortfolio::portfolioSpec()` function. This object defines the characteristics and constraints of the portfolio for optimization.

- The portfolio type is set as CVaR by using the `fPortfolio::setType()` function and assigning it the value of "CVaR".

- The linear programming solver for CVaR optimization is set using the `fPortfolio::setSolver()` function. In this case, the "solveRglpk.CVAR" solver is used.

- The CVaR alpha level is set to 0.025 (equivalent to CVaR at the 0.95 quantile) using the `fPortfolio::setAlpha()` function.

- The daily target return constraint is set to the value of `targetReturn` using the `fPortfolio::setTargetReturn()` function.

```{r, echo=TRUE, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE}
##### Setting up a fPortfolio min CVaR optimization
cvar_opt <- matrix(nrow = length(index_vector) - 1, ncol = N)  # Matrix to store CVaR optimization results
targetReturn <- 0  # Daily target return constraint
targetReturn <- 0  # Daily target return constraint
frontierSpec <- fPortfolio::portfolioSpec()  # Portfolio specification for optimization
fPortfolio::setType(frontierSpec) <- "CVaR"  # Set portfolio type as CVaR
fPortfolio::setSolver(frontierSpec) <- "solveRglpk.CVAR"  # Use linear programming solver for CVaR optimization
fPortfolio::setAlpha(frontierSpec) <- 0.025  # Set CVaR alpha level as 0.05 (CVaR_0.95)
fPortfolio::setTargetReturn(frontierSpec) <- targetReturn  # Set the daily target return constraint
```

# Iterating over n assets

The code snippet performs an iteration over a set of assets to optimize the portfolio using copula-based simulations.

- A series of matrices and lists are initialized to store the forecasts and optimization results.

- The iteration starts from the second index of the `index_vector` and loops through each asset.

- Within the loop, several calculations are performed for each asset:

  - A subset of returns data for the specific asset is extracted.
  
  - A GARCH model is fitted to the subset of returns data using the `rugarch::ugarchfit()` function. The resulting residuals, sigma forecasts, and GARCH coefficients are stored.
  
  - Initial parameter estimates for the copula models are obtained by fitting the copulas to the uniform distribution of the GARCH residuals.
  
  - Non-linear constrained optimization is performed using the `Rsolnp::solnp()` function. The `LLCG` function represents the negative log-likelihood to be maximized, and the `eqfun` function ensures that the weights of the copulas sum up to 1. The optimization parameters and copula variates are stored.
  
  - For each asset, copula variates are generated using the estimated copula parameters.
  
  - The dependence structure is combined using a linear combination of copula variates.
  
  - Predictions for returns, mean, and sigma are made based on the GARCH model and the copula variates.
  
  - The portfolio is optimized using the simulated returns for each asset during the specific optimization period.
  
  - The resulting weights are stored in the `cvar_opt` matrix.
  
  - Portfolio returns are calculated based on the weights, and daily portfolio returns are stored in the `portfolio_daily_returns` matrix.

- The iteration continues until all assets have been processed.

```{r, echo=TRUE, eval=TRUE, include=TRUE, message=FALSE, warning=FALSE}
# Iterating over n assets
for (i in 2:length(index_vector)) {
  
  # Matrix to save sigma forecasts
  unif_dist <- garch_pred <- sigma <- residuals <- matrix(nrow = K, ncol = N)
  garch_coef <- vector("list", length = N)
  
  t1 <- index_vector[i - 1]
  t2 <- index_vector[i] - 1
  
  # Looping through each asset
  for (j in 1:length(names_vector)) {
    x <- cbind(returns[t1:t2, (j + 1)])
    
    # Fitting GARCH model
    garch_fit <- try(rugarch::ugarchfit(mod_garch, data = x, solver = "hybrid"),
                     silent = TRUE)
    
    residuals[, j] <- garch_fit@fit$residuals
    sigma[, j] <- garch_fit@fit$sigma
    garch_coef[[j]] <- garch_fit@fit$coef
    unif_dist[, j] <- fGarch::psstd(q = residuals[, j] / sigma[, j],
                                    nu = garch_coef[[j]][6],
                                    xi = garch_coef[[j]][5])
  }
  
  ## Creating elliptical copula objects and estimating "initial guesses" for each copula parameter.
  # Then, we maximize loglikelihood of the linear combination of the three copulas
  par1 <- copula::fitCopula(copC, unif_dist, "itau", estimate.variance = TRUE)@estimate # Inversion of Kendall's tau for Clayton
  par2 <- copula::fitCopula(copG, unif_dist, "itau", estimate.variance = TRUE)@estimate # Inversion of Kendall's tau for Gumbel
  par3 <- copula::fitCopula(copt, unif_dist, "mpl", estimate.variance = FALSE)@estimate # MPL to estimate Degrees of Freedom (DF)
  
  ## Non-linear constrained optimization (RSOLNP)
  opt <- Rsolnp::solnp(pars = c(par1, par2, par3, par4, par5, par6),
                       fun = LLCG,
                       LB = lower,
                       UB = upper,
                       copt = copt,
                       copC = copC,
                       copG = copG,
                       U = unif_dist,
                       eqfun = eqfun,
                       eqB = c(1)) # RSOLNP
  
  ## Saving optimization parameters in a list
  cop_param <- opt$pars
  
  # Clayton, t, gumbel, and ctg variates matrix
  ctg <- Cc <- Cg <- Ct <- matrix(nrow = K, ncol = N)
  
  ## Generating copula variates
  Cc[, ] <- cop_param[5] * copula::rCopula(n = K,
                                           copula = copula::claytonCopula(param = cop_param[1],
                                                                          dim = N))
  Cg[, ] <- cop_param[6] * copula::rCopula(n = K,
                                           copula = copula::gumbelCopula(param = cop_param[2],
                                                                         dim = N))
  Ct[, ] <- cop_param[7] * copula::rCopula(n = K,
                                           copula = copula::tCopula(param = cop_param[3],
                                                                    df = cop_param[4],
                                                                    dim = N))
  
  # Linear combination of copula varieties
  ctg <- Cc + Ct + Cg
  
  # For each asset, generate copula 'z' dependence structure
  rtn_pred <- mean_pred <- sigma_pred <- zsim <- matrix(nrow = K, ncol = N)
  for (j in 1:N) {
    
    zsim[, j] <- fGarch::qsstd(ctg[, j],
                               nu = garch_coef[[j]][6],
                               xi = garch_coef[[j]][5]) /
      sd(fGarch::qsstd(ctg[, j], nu = garch_coef[[j]][6],
                       xi = garch_coef[[j]][5]))
    
    rtn_t <- as.numeric(returns[(t2 - 1), (j + 1)])
    sigma_t <- sigma[K, j]
    
    sigma_pred[1, j] <- sqrt(garch_coef[[j]][7] +  # omega
                               garch_coef[[j]][3] * (rtn_t)^2 +  # alpha1
                               garch_coef[[j]][4] * (sigma_t)^2)  # beta1
    mean_pred[1, j] <- garch_coef[[j]][1] + garch_coef[[j]][2] * rtn_t  # mu and ar1
    rtn_pred[1, j] <- mean_pred[1, j] + sigma_pred[1, j] * zsim[1, j]
    
    for (t in 2:K) {
      sigma_pred[t, j] <- sqrt(garch_coef[[j]][7] +  # omega
                                 garch_coef[[j]][3] * (rtn_pred[(t - 1), j])^2 +  # alpha1
                                 garch_coef[[j]][4] * (sigma_pred[(t - 1), j])^2)  # beta1
      mean_pred[t, j] <- garch_coef[[j]][1] + garch_coef[[j]][2] * rtn_pred[(t - 1), j]  # mu and ar1
      rtn_pred[t, j] <- mean_pred[t, j] + sigma_pred[t, j] * zsim[t, j]
    }
  }
  
  ## Optimizing portfolio using K simulated returns for each asset, for optimization period i
  retornfPort <- as.timeSeries(rtn_pred[, 1:N])
  frontier1g <- fPortfolio::efficientPortfolio(data = retornfPort,
                                               spec = frontierSpec,
                                               constraints = "LongOnly")
  cvar_opt[(i - 1), 1:N] <- fPortfolio::getWeights(frontier1g)  # Storing resulting weights
  
  # Calculate portfolio returns
  t1 <- t1+K
  t2 <- min(nrow(returns), t2+K)
  portfolio_returns <- as.matrix(returns[t1:t2, names_vector]) %*% t(cvar_opt[(-1), ])
  portfolio_daily_returns[t1:t2, ] <- rowSums(portfolio_returns)
  
}

```



















